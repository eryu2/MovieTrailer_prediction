{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 15:27:10.500553: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복확인...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>순위</th>\n",
       "      <th>영화제목</th>\n",
       "      <th>movie_code</th>\n",
       "      <th>관객수</th>\n",
       "      <th>누적관객수</th>\n",
       "      <th>매출액</th>\n",
       "      <th>누적매출액</th>\n",
       "      <th>개봉일</th>\n",
       "      <th>개봉후N일</th>\n",
       "      <th>...</th>\n",
       "      <th>배우</th>\n",
       "      <th>제작사</th>\n",
       "      <th>url</th>\n",
       "      <th>best</th>\n",
       "      <th>제거</th>\n",
       "      <th>collected</th>\n",
       "      <th>text</th>\n",
       "      <th>file_num</th>\n",
       "      <th>multi_text</th>\n",
       "      <th>new_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [날짜, 순위, 영화제목, movie_code, 관객수, 누적관객수, 매출액, 누적매출액, 개봉일, 개봉후N일, 장르, 감독, 배우, 제작사, url, best, 제거, collected, text, file_num, multi_text, new_genre]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_parquet('Data/movie_list/201701-202310_movielist_cumbyDay.parquet').query(\"개봉후N일 == 7 \") \n",
    "print(\"중복확인...\")\n",
    "display(data[data['movie_code'].duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상위/하위 20.0% : 각각 58 개\n",
      "Best 영화 샘플:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영화제목</th>\n",
       "      <th>movie_code</th>\n",
       "      <th>누적관객수</th>\n",
       "      <th>file_num</th>\n",
       "      <th>text</th>\n",
       "      <th>multi_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>신과함께-인과 연</td>\n",
       "      <td>20186202</td>\n",
       "      <td>7734966</td>\n",
       "      <td>6.0</td>\n",
       "      <td>여기 있는 망적 김수홍의 재판을 허락해 주십시오 그의 죽음은 밝혀야 될 진실이 있습...</td>\n",
       "      <td>하정우, 주지훈. 리얼라이즈픽쳐스(주), (주)덱스터스튜디오. 여기 있는 망적 김수...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>탐정: 리턴즈</td>\n",
       "      <td>20178161</td>\n",
       "      <td>1304215</td>\n",
       "      <td>7.0</td>\n",
       "      <td>제발 출발 어디로. 사무실 운영도 못해 사람들이 그렇게 인내심이 없어서 큰일들 하시...</td>\n",
       "      <td>권상우, 성동일. (주)크리픽쳐스, (주)씨제이이엔엠. 제발 출발 어디로. 사무실 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>신과함께-죄와 벌</td>\n",
       "      <td>20150976</td>\n",
       "      <td>5696686</td>\n",
       "      <td>9.0</td>\n",
       "      <td>전 귀인이 아닙니다. 난 아저씨 직업 선택이 신의 한수였다고 봐 저의 만 8번째 균...</td>\n",
       "      <td>하정우, 차태현. 리얼라이즈픽쳐스(주), (주)덱스터스튜디오. 전 귀인이 아닙니다....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            영화제목  movie_code    누적관객수  file_num  \\\n",
       "index                                             \n",
       "0      신과함께-인과 연    20186202  7734966       6.0   \n",
       "63       탐정: 리턴즈    20178161  1304215       7.0   \n",
       "3      신과함께-죄와 벌    20150976  5696686       9.0   \n",
       "\n",
       "                                                    text  \\\n",
       "index                                                      \n",
       "0      여기 있는 망적 김수홍의 재판을 허락해 주십시오 그의 죽음은 밝혀야 될 진실이 있습...   \n",
       "63     제발 출발 어디로. 사무실 운영도 못해 사람들이 그렇게 인내심이 없어서 큰일들 하시...   \n",
       "3      전 귀인이 아닙니다. 난 아저씨 직업 선택이 신의 한수였다고 봐 저의 만 8번째 균...   \n",
       "\n",
       "                                              multi_text  \n",
       "index                                                     \n",
       "0      하정우, 주지훈. 리얼라이즈픽쳐스(주), (주)덱스터스튜디오. 여기 있는 망적 김수...  \n",
       "63     권상우, 성동일. (주)크리픽쳐스, (주)씨제이이엔엠. 제발 출발 어디로. 사무실 ...  \n",
       "3      하정우, 차태현. 리얼라이즈픽쳐스(주), (주)덱스터스튜디오. 전 귀인이 아닙니다....  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Worst 영화 샘플:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영화제목</th>\n",
       "      <th>movie_code</th>\n",
       "      <th>누적관객수</th>\n",
       "      <th>file_num</th>\n",
       "      <th>text</th>\n",
       "      <th>multi_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>잃어버린 얼굴 1895</td>\n",
       "      <td>20215809</td>\n",
       "      <td>4913</td>\n",
       "      <td>10.0</td>\n",
       "      <td>조선의 마지막 왕비 명성황후의 사진을 찾으시는군요 문두 마주쳐서 안 돼 왕비마마의 ...</td>\n",
       "      <td>차지연, 김용한. (재)서울예술단, (재)서울예술단. 조선의 마지막 왕비 명성황후의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>우리 사랑이 향기로 남을 때</td>\n",
       "      <td>20239884</td>\n",
       "      <td>9782</td>\n",
       "      <td>14.0</td>\n",
       "      <td>내가 악착같이이 시간에 버스를 타야만 하는 이유가 있다 그녀다 내 삶에 유일한 소망...</td>\n",
       "      <td>윤시윤, 최훈재. (주)도깨비미디어, 주식회사 콘텐츠존. 내가 악착같이이 시간에 버...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>썬키스 패밀리</td>\n",
       "      <td>20166301</td>\n",
       "      <td>30709</td>\n",
       "      <td>19.0</td>\n",
       "      <td>야 5,000원. 오빠 이치 이하 이런 미친 아줌마랑 모이냐니까 뭘 몰라이야. 이뻐...</td>\n",
       "      <td>박희순, 진경. (주)영화사두둥, 플러스엠 엔터테인먼트. 야 5,000원. 오빠 이...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  영화제목  movie_code  누적관객수  file_num  \\\n",
       "index                                                 \n",
       "374       잃어버린 얼굴 1895    20215809   4913      10.0   \n",
       "357    우리 사랑이 향기로 남을 때    20239884   9782      14.0   \n",
       "322            썬키스 패밀리    20166301  30709      19.0   \n",
       "\n",
       "                                                    text  \\\n",
       "index                                                      \n",
       "374    조선의 마지막 왕비 명성황후의 사진을 찾으시는군요 문두 마주쳐서 안 돼 왕비마마의 ...   \n",
       "357    내가 악착같이이 시간에 버스를 타야만 하는 이유가 있다 그녀다 내 삶에 유일한 소망...   \n",
       "322    야 5,000원. 오빠 이치 이하 이런 미친 아줌마랑 모이냐니까 뭘 몰라이야. 이뻐...   \n",
       "\n",
       "                                              multi_text  \n",
       "index                                                     \n",
       "374    차지연, 김용한. (재)서울예술단, (재)서울예술단. 조선의 마지막 왕비 명성황후의...  \n",
       "357    윤시윤, 최훈재. (주)도깨비미디어, 주식회사 콘텐츠존. 내가 악착같이이 시간에 버...  \n",
       "322    박희순, 진경. (주)영화사두둥, 플러스엠 엔터테인먼트. 야 5,000원. 오빠 이...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_text shape: (116,)\n",
      "y shape: (116,)\n",
      "best_array 생성시작...\n",
      "worst_array 생성시작...\n",
      "X_image shape: (116, 60, 224, 224, 3)\n",
      "y shape: (116,)\n",
      "best_array 생성시작...\n",
      "worst_array 생성시작...\n",
      "X_audio shape: (116, 7500, 40)\n",
      "y shape: (116,)\n"
     ]
    }
   ],
   "source": [
    "from NumpyCreator import *\n",
    "\n",
    "ratio=0.2   #상위, 하위 20% 영화 대상 \n",
    "Generator = NumpyCreator(data, ratio)\n",
    "X_text, X_image, X_audio, y = Generator.generate_data(multitext=True, architecture='MobileNet') \n",
    "# X_audio, y = Generator.generate_audio()  #오디오 데이터만 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_text_train shape: (81,)\n",
      "X_text_test shape: (35,)\n",
      "X_image_train shape: (81, 60, 224, 224, 3)\n",
      "X_image_test shape: (35, 60, 224, 224, 3)\n",
      "X_audio_train shape: (81, 7500, 40)\n",
      "X_audio_test shape: (35, 7500, 40)\n",
      "y_train: (81, 2)\n",
      "y_test: (35, 2)\n"
     ]
    }
   ],
   "source": [
    "from trailerDataSplitter import trailerDataSplitter\n",
    "\n",
    "### audio만 사용할때 ###\n",
    "# splitter = trailerDataSplitter(y, X_audio=X_audio, test_size=0.3, random_state=42, stratify=y)\n",
    "# X_text_train, X_text_test, X_image_train, X_image_test, X_audio_train, X_audio_test, y_train, y_test = splitter.custom_train_test_split()\n",
    "\n",
    "### text, image, audio 모두 사용할때 ###\n",
    "splitter = trailerDataSplitter(y, X_text, X_image, X_audio, test_size=0.3, random_state=42, stratify=y)\n",
    "X_text_train, X_text_test, X_image_train, X_image_test, X_audio_train, X_audio_test, y_train, y_test = splitter.custom_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 00:41:31.179043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21723 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base-v2022\")\n",
    "MAX_LEN = 100\n",
    "X_train_tokenized = tokenizer(list(X_text_train), return_tensors='tf',max_length=MAX_LEN, truncation=True, padding='max_length')\n",
    "X_test_tokenized = tokenizer(list(X_text_test), return_tensors='tf',max_length=MAX_LEN,truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:32.483939: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:41:32.484020: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:41:32.484099: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:41:32.484158: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:41:32.484217: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:41:32.484266: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:41:32.484617: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:41:32.536860: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:32.600421: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:225] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2024-03-12 00:41:32.600554: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:228] Used ptxas at ptxas\n",
      "2024-03-12 00:41:32.600820: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:32.661957: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:32.727593: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:32.846588: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:41:32.848565: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:32.911944: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:32.984954: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:41:33.030582: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:41:33.264522: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:33.387540: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:41:34.671650: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:34.834381: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'electra.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFElectraModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFElectraModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from MultiModalClassifier import MultiModalClassifier_audio\n",
    "BACKBONE = 'MobileNet'\n",
    "model = MultiModalClassifier_audio(BACKBONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 00:41:37.353703: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:37.450793: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:41:37.450865: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:41:37.522333: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:37.615594: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:41:37.626760: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:41:37.697160: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:37.791431: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:41:37.817260: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:37.983508: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:41:38.010371: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:38.177359: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:41:38.203061: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:38.367992: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:41:38.393159: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:38.551863: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 00:41:46.842394: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:41:47.072647: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:10.490193: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-03-12 00:42:10.664376: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:10.794172: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:42:10.919199: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:11.053854: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:11.057389: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:42:11.183631: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:11.188127: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:42:11.310711: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:11.319343: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:42:11.438648: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:11.440099: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:11.561008: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:11.565934: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:11.697533: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:11.700178: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:11.703259: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:11.836902: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:11.959104: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:12.404710: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:12.613704: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:42:12.735237: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:12.784836: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:42:12.906842: W external/local_xla/xla/stream_executor/gpu/redzone_allocator.cc:322] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:13.052185: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:13.106412: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:13.360264: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:42:13.482010: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:13.626490: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:15.025551: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:15.301302: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:15.406847: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:15.543157: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:42:15.544824: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:15.816018: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:15.818716: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:15.953223: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-03-12 00:42:15.954814: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:16.084903: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:16.089763: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:16.230055: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:16.233333: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:16.363559: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:16.366713: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:16.511078: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:16.527456: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:16.656518: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:16.859090: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:17.129229: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-03-12 00:42:17.149575: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f37dba60840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-12 00:42:17.149606: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-03-12 00:42:17.155514: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-12 00:42:17.190655: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710171737.479777   62382 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-03-12 00:42:17.515964: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:17.840464: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:18.189338: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:18.541866: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:18.893118: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:19.234017: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:19.557298: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:19.916755: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:20.254109: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:20.412180: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:20.557506: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:20.794104: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:21.200734: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:21.451185: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:21.808069: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:21.963856: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:22.365296: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:22.525529: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:22.741539: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:22.962473: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:23.237959: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:23.484451: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:23.909982: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:24.182892: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:24.501756: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:24.904371: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:26.351709: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:26.715567: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:27.125411: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:27.761492: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:28.244266: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:28.644831: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:30.088734: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:30.478309: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:30.901535: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:31.510802: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:32.093144: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:33.990987: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:34.367701: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:34.775196: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:35.413633: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:35.910156: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:36.337867: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:37.785336: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:38.178696: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:38.628907: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:39.149050: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:39.506579: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:39.727702: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:40.133612: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:40.334755: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:40.780750: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:41.814344: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:42.276930: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:43.290953: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:44.154185: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:44.675937: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:45.428925: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/36 [==>...........................] - ETA: 7s - loss: 6.1297 - accuracy: 0.5000 - f1_score: 0.5000  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 00:42:46.722795: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 2.2049 - accuracy: 0.4444 - f1_score: 0.4286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 00:42:58.275917: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-03-12 00:42:58.612148: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 79s 468ms/step - loss: 2.2049 - accuracy: 0.4444 - f1_score: 0.4286 - val_loss: 0.8813 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 10s 291ms/step - loss: 0.7833 - accuracy: 0.4861 - f1_score: 0.4812 - val_loss: 0.7442 - val_accuracy: 0.3333 - val_f1_score: 0.3250\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 10s 275ms/step - loss: 0.6952 - accuracy: 0.6250 - f1_score: 0.6249 - val_loss: 0.7313 - val_accuracy: 0.2222 - val_f1_score: 0.2222\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 10s 275ms/step - loss: 0.7102 - accuracy: 0.4861 - f1_score: 0.4812 - val_loss: 0.7164 - val_accuracy: 0.3333 - val_f1_score: 0.3250\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 8s 209ms/step - loss: 0.6932 - accuracy: 0.5556 - f1_score: 0.5524 - val_loss: 0.7205 - val_accuracy: 0.3333 - val_f1_score: 0.3250\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 8s 215ms/step - loss: 0.6948 - accuracy: 0.6389 - f1_score: 0.6247 - val_loss: 0.7206 - val_accuracy: 0.2222 - val_f1_score: 0.1818\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 10s 278ms/step - loss: 0.6654 - accuracy: 0.6389 - f1_score: 0.6286 - val_loss: 0.7082 - val_accuracy: 0.3333 - val_f1_score: 0.2500\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 8s 213ms/step - loss: 0.6985 - accuracy: 0.5417 - f1_score: 0.5262 - val_loss: 0.7126 - val_accuracy: 0.3333 - val_f1_score: 0.3250\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.6804 - accuracy: 0.6111 - f1_score: 0.6111 - val_loss: 0.7290 - val_accuracy: 0.2222 - val_f1_score: 0.1818\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 8s 209ms/step - loss: 0.6608 - accuracy: 0.6667 - f1_score: 0.6444 - val_loss: 0.7286 - val_accuracy: 0.4444 - val_f1_score: 0.3077\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.6438 - accuracy: 0.7222 - f1_score: 0.7113 - val_loss: 0.7154 - val_accuracy: 0.6667 - val_f1_score: 0.6667\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 10s 271ms/step - loss: 0.5849 - accuracy: 0.8472 - f1_score: 0.8448 - val_loss: 0.6623 - val_accuracy: 0.4444 - val_f1_score: 0.4156\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 10s 274ms/step - loss: 0.5992 - accuracy: 0.8333 - f1_score: 0.8312 - val_loss: 0.6407 - val_accuracy: 0.4444 - val_f1_score: 0.3077\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 10s 270ms/step - loss: 0.5872 - accuracy: 0.8889 - f1_score: 0.8881 - val_loss: 0.6288 - val_accuracy: 0.4444 - val_f1_score: 0.3077\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.5677 - accuracy: 0.9028 - f1_score: 0.9026 - val_loss: 0.6802 - val_accuracy: 0.4444 - val_f1_score: 0.3077\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 10s 277ms/step - loss: 0.5716 - accuracy: 0.9444 - f1_score: 0.9444 - val_loss: 0.5821 - val_accuracy: 0.6667 - val_f1_score: 0.6494\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.5624 - accuracy: 0.8472 - f1_score: 0.8465 - val_loss: 0.5856 - val_accuracy: 0.7778 - val_f1_score: 0.7750\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 8s 213ms/step - loss: 0.5491 - accuracy: 0.8889 - f1_score: 0.8885 - val_loss: 0.6954 - val_accuracy: 0.4444 - val_f1_score: 0.3077\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.5232 - accuracy: 0.9306 - f1_score: 0.9304 - val_loss: 0.6158 - val_accuracy: 0.6667 - val_f1_score: 0.6494\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.5365 - accuracy: 0.9444 - f1_score: 0.9444 - val_loss: 0.6021 - val_accuracy: 0.6667 - val_f1_score: 0.6494\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 10s 280ms/step - loss: 0.5367 - accuracy: 0.8889 - f1_score: 0.8881 - val_loss: 0.5561 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.5367 - accuracy: 0.9028 - f1_score: 0.9023 - val_loss: 0.5568 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.5226 - accuracy: 0.8750 - f1_score: 0.8744 - val_loss: 0.6272 - val_accuracy: 0.6667 - val_f1_score: 0.6494\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 10s 273ms/step - loss: 0.5175 - accuracy: 0.8889 - f1_score: 0.8875 - val_loss: 0.5519 - val_accuracy: 0.6667 - val_f1_score: 0.6494\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.5522 - accuracy: 0.9167 - f1_score: 0.9164 - val_loss: 0.5707 - val_accuracy: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.5095 - accuracy: 0.8889 - f1_score: 0.8885 - val_loss: 0.5568 - val_accuracy: 0.8889 - val_f1_score: 0.8831\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 10s 270ms/step - loss: 0.5007 - accuracy: 0.9167 - f1_score: 0.9164 - val_loss: 0.5491 - val_accuracy: 0.8889 - val_f1_score: 0.8831\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.5074 - accuracy: 0.9306 - f1_score: 0.9304 - val_loss: 0.8540 - val_accuracy: 0.4444 - val_f1_score: 0.3077\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.4742 - accuracy: 0.9306 - f1_score: 0.9302 - val_loss: 0.5543 - val_accuracy: 0.7778 - val_f1_score: 0.7750\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 10s 271ms/step - loss: 0.5184 - accuracy: 0.9028 - f1_score: 0.9028 - val_loss: 0.5285 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.5258 - accuracy: 0.9444 - f1_score: 0.9444 - val_loss: 0.6493 - val_accuracy: 0.5556 - val_f1_score: 0.5000\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 10s 275ms/step - loss: 0.5017 - accuracy: 0.9722 - f1_score: 0.9722 - val_loss: 0.5149 - val_accuracy: 0.8889 - val_f1_score: 0.8831\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 10s 270ms/step - loss: 0.4712 - accuracy: 0.9583 - f1_score: 0.9583 - val_loss: 0.4790 - val_accuracy: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 10s 270ms/step - loss: 0.4472 - accuracy: 0.9861 - f1_score: 0.9861 - val_loss: 0.4686 - val_accuracy: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 10s 272ms/step - loss: 0.5048 - accuracy: 0.9167 - f1_score: 0.9161 - val_loss: 0.4598 - val_accuracy: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 8s 212ms/step - loss: 0.4983 - accuracy: 0.9306 - f1_score: 0.9304 - val_loss: 0.4773 - val_accuracy: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.4531 - accuracy: 0.8889 - f1_score: 0.8881 - val_loss: 0.4670 - val_accuracy: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 10s 270ms/step - loss: 0.4075 - accuracy: 0.9722 - f1_score: 0.9721 - val_loss: 0.4526 - val_accuracy: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.4434 - accuracy: 0.9306 - f1_score: 0.9304 - val_loss: 0.4527 - val_accuracy: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.4980 - accuracy: 0.8750 - f1_score: 0.8748 - val_loss: 0.4781 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.4557 - accuracy: 0.9583 - f1_score: 0.9583 - val_loss: 0.4674 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.4652 - accuracy: 0.9444 - f1_score: 0.9443 - val_loss: 0.4710 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.4678 - accuracy: 0.9444 - f1_score: 0.9444 - val_loss: 0.4966 - val_accuracy: 0.7778 - val_f1_score: 0.7750\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.4502 - accuracy: 0.8889 - f1_score: 0.8888 - val_loss: 0.4604 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 10s 280ms/step - loss: 0.4650 - accuracy: 0.9444 - f1_score: 0.9441 - val_loss: 0.4372 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.4382 - accuracy: 0.8889 - f1_score: 0.8875 - val_loss: 0.4976 - val_accuracy: 0.7778 - val_f1_score: 0.7750\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 8s 212ms/step - loss: 0.4465 - accuracy: 0.9722 - f1_score: 0.9721 - val_loss: 0.4875 - val_accuracy: 0.7778 - val_f1_score: 0.7750\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.4125 - accuracy: 0.9861 - f1_score: 0.9861 - val_loss: 0.4422 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 49/100\n",
      " 7/36 [====>.........................] - ETA: 5s - loss: 0.5189 - accuracy: 0.8571 - f1_score: 0.8444"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 00:49:40.562890: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 7.5.17, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 10s 288ms/step - loss: 0.4386 - accuracy: 0.9444 - f1_score: 0.9443 - val_loss: 0.4135 - val_accuracy: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 10s 274ms/step - loss: 0.4277 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.4024 - val_accuracy: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.4590 - accuracy: 0.9167 - f1_score: 0.9161 - val_loss: 0.4119 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.3995 - accuracy: 0.9861 - f1_score: 0.9861 - val_loss: 0.4041 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 8s 209ms/step - loss: 0.4071 - accuracy: 0.9722 - f1_score: 0.9721 - val_loss: 0.4398 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.4351 - accuracy: 0.9306 - f1_score: 0.9302 - val_loss: 0.4371 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.4377 - accuracy: 0.9861 - f1_score: 0.9861 - val_loss: 0.4916 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.4079 - accuracy: 0.8750 - f1_score: 0.8744 - val_loss: 0.7082 - val_accuracy: 0.5556 - val_f1_score: 0.5000\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 10s 269ms/step - loss: 0.4423 - accuracy: 0.9306 - f1_score: 0.9302 - val_loss: 0.4002 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 10s 271ms/step - loss: 0.3994 - accuracy: 0.9722 - f1_score: 0.9722 - val_loss: 0.3865 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.4001 - accuracy: 0.9722 - f1_score: 0.9722 - val_loss: 0.4575 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.3649 - accuracy: 0.9861 - f1_score: 0.9861 - val_loss: 0.4430 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 10s 269ms/step - loss: 0.4468 - accuracy: 0.9028 - f1_score: 0.9023 - val_loss: 0.3769 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 10s 270ms/step - loss: 0.3958 - accuracy: 0.9583 - f1_score: 0.9583 - val_loss: 0.3707 - val_accuracy: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 10s 277ms/step - loss: 0.4309 - accuracy: 0.9306 - f1_score: 0.9304 - val_loss: 0.3612 - val_accuracy: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.4147 - accuracy: 0.9444 - f1_score: 0.9444 - val_loss: 0.3672 - val_accuracy: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.3636 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.4282 - accuracy: 0.9583 - f1_score: 0.9583 - val_loss: 0.4372 - val_accuracy: 0.7778 - val_f1_score: 0.7750\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.3703 - accuracy: 0.9722 - f1_score: 0.9722 - val_loss: 0.6234 - val_accuracy: 0.6667 - val_f1_score: 0.6494\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.3852 - accuracy: 0.9444 - f1_score: 0.9443 - val_loss: 0.6875 - val_accuracy: 0.6667 - val_f1_score: 0.6494\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.3827 - accuracy: 0.9722 - f1_score: 0.9722 - val_loss: 0.7539 - val_accuracy: 0.5556 - val_f1_score: 0.3571\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.3631 - accuracy: 0.9722 - f1_score: 0.9722 - val_loss: 1.2204 - val_accuracy: 0.4444 - val_f1_score: 0.3077\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.4221 - accuracy: 0.9028 - f1_score: 0.9019 - val_loss: 0.4100 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.3732 - accuracy: 0.9444 - f1_score: 0.9443 - val_loss: 0.4241 - val_accuracy: 0.8889 - val_f1_score: 0.8889\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 8s 209ms/step - loss: 0.4105 - accuracy: 0.9444 - f1_score: 0.9444 - val_loss: 0.4674 - val_accuracy: 0.7778 - val_f1_score: 0.7750\n",
      "Epoch 73: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    checkpoint_filepath = \"/home/dlwnsfls/deepLearning_project/Entto/checkpoints\"\n",
    "    mc = ModelCheckpoint(checkpoint_filepath, monitor='val_loss', mode='min',\n",
    "                        save_best_only=True, save_weights_only=True)\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                                                            initial_learning_rate=7e-6,\n",
    "                                                            decay_steps=10000,\n",
    "                                                            decay_rate=0.9)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', F1Score(num_classes=2, average='macro')])\n",
    "    history = model.fit(\n",
    "                        {\n",
    "                            'text_embeddings': dict(X_train_tokenized), \n",
    "                            'image_embeddings': X_image_train,\n",
    "                            'audio_embeddings': X_audio_train\n",
    "                            \n",
    "                            }, \n",
    "                                y_train,\n",
    "                                epochs=100,\n",
    "                                batch_size=2,\n",
    "                                callbacks=[es, mc],\n",
    "                                validation_split=0.1,\n",
    "                                \n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3fd1630580>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3mUlEQVR4nO3dd3hU1dbH8e+kTUggCQESQg299x6KIE1Q7IINxY6iotgulqvIfUXvtQBiF0UsgEpVUIpKkyYlSC9SAiEhtCQkpOe8fxxmkpBCEpKclN/neebJzJkzZ/YOZdbsvfZeNsMwDEREREQqEBerGyAiIiJS0hQAiYiISIWjAEhEREQqHAVAIiIiUuEoABIREZEKRwGQiIiIVDgKgERERKTCcbO6AaVReno6J06coEqVKthsNqubIyIiIvlgGAbnz5+nVq1auLjkPcajACgHJ06coG7dulY3Q0RERArh2LFj1KlTJ89zFADloEqVKoD5C/Tx8bG4NSIiIpIfsbGx1K1b1/k5nhcFQDlwTHv5+PgoABIRESlj8pO+oiRoERERqXAUAImIiEiFY2kANGnSJLp06UKVKlUICAjgxhtvZN++fXm+Zt68eQwcOJAaNWrg4+NDjx49WLp0aZZzZsyYgc1my3ZLTEwszu6IiIhIGWFpDtCqVasYM2YMXbp0ITU1lZdeeolBgwaxe/duvL29c3zN6tWrGThwIG+88QZ+fn58+eWXDBs2jI0bN9KhQwfneT4+PtmCKU9Pz2Ltj4iISH6kpaWRkpJidTPKJA8Pj8succ8Pm2EYRhG0p0icOnWKgIAAVq1aRZ8+ffL9ulatWjFixAj+/e9/A+YI0FNPPUV0dHSh2hEbG4uvry8xMTFKghYRkSJjGAaRkZGF/nwScHFxoUGDBnh4eGR7riCf36VqFVhMTAwA/v7++X5Neno658+fz/aauLg46tevT1paGu3bt2fixIlZRogyS0pKIikpyfk4Nja2EK0XERHJmyP4CQgIwMvLS5vtFpBjo+KIiAjq1at3Rb+/UhMAGYbBuHHj6NWrF61bt87369555x3i4+MZPny481jz5s2ZMWMGbdq0ITY2lilTptCzZ0+2b99OkyZNsl1j0qRJTJgwoUj6ISIikpO0tDRn8FOtWjWrm1Nm1ahRgxMnTpCamoq7u3uhr1NqpsDGjBnD4sWLWbt27WV3b3SYNWsWDz74IAsXLmTAgAG5npeenk7Hjh3p06cPU6dOzfZ8TiNAdevW1RSYiIgUmcTERA4fPkxwcDCVKlWyujllVkJCAkeOHKFBgwbZcnvL3BTYE088waJFi1i9enW+g585c+bwwAMP8MMPP+QZ/IA5X9ilSxcOHDiQ4/N2ux273V7gdouIiBSUpr2uTFH9/ixdBm8YBo8//jjz5s3j999/p0GDBvl63axZsxg1ahTfffcd1157bb7eJzQ0lKCgoCttsoiIiJQDlo4AjRkzhu+++46FCxdSpUoVIiMjAfD19XUOD44fP57w8HBmzpwJmMHPPffcw5QpU+jevbvzNZUqVcLX1xeACRMm0L17d5o0aUJsbCxTp04lNDSUDz74wIJeioiISGlj6QjQRx99RExMDH379iUoKMh5mzNnjvOciIgIwsLCnI8/+eQTUlNTGTNmTJbXjB071nlOdHQ0Dz/8MC1atGDQoEGEh4ezevVqunbtWqL9ExERkayCg4OZPHmy1c0oPUnQpUlx7QOUlJrGmbhkAGr5KQFORKQicSRB55S8W9r17duX9u3bF0ngcurUKby9vfHy8irU6/P6PRbk81u1wErQjuMxhLz5O3d+tsHqpoiIiBQZwzBITU3N17k1atQodPBTlBQAlSB3V/PXnZKmQTcRkYrOMAwuJKdacivI5M+oUaNYtWoVU6ZMcdbWdNTcXLp0KZ07d8Zut7NmzRr++ecfbrjhBgIDA6lcuTJdunRhxYoVWa536RSYzWbj888/56abbsLLy4smTZqwaNGiovo156pULIOvKBwBUHJausUtERERqyWkpNHy30svf2Ix2P36YLw88hcCTJkyhf3799O6dWtef/11AHbt2gXA888/z9tvv03Dhg3x8/Pj+PHjDB06lP/85z94enry1VdfMWzYMPbt20e9evVyfY8JEybw3//+l//973+8//773HXXXRw9erRAlSEKSiNAJcjDzTECpABIRETKBl9fXzw8PPDy8qJmzZrUrFkTV1dXAF5//XUGDhxIo0aNqFatGu3ateORRx6hTZs2NGnShP/85z80bNjwsiM6o0aN4o477qBx48a88cYbxMfHs2nTpmLtl0aASpCHYwosVQGQiEhFV8ndld2vD7bsvYtC586dszyOj49nwoQJ/Pzzz85yFQkJCVlWc+ekbdu2zvve3t5UqVKFqKioImljbhQAlSB3N3P3Sk2BiYiIzWbL9zRUaeXt7Z3l8XPPPcfSpUt5++23ady4MZUqVeLWW28lOTk5z+tcWtPLZrORnl68n5Vl+zdfxmROgjYMQ9uhi4hImeDh4UFaWtplz1uzZg2jRo3ipptuAiAuLo4jR44Uc+sKRzlAJcgRAIFWgomISNkRHBzMxo0bOXLkCKdPn851dKZx48bMmzeP0NBQtm/fzp133lnsIzmFpQCoBNndMgdApfMvhIiIyKWeffZZXF1dadmyJTVq1Mg1p+e9996jatWqhISEMGzYMAYPHkzHjh1LuLX5oymwEpR1BEgBkIiIlA1NmzZl/fr1WY6NGjUq23nBwcH8/vvvWY6NGTMmy+NLp8Ry2pMoOjq6UO0sCI0AlSBXFxsuF9N+lAgtIiJiHQVAJcy5GaKWwouIiFhGAVAJ81A5DBEREcspACph7toNWkRExHIKgEqYh6bARERELKcAqIQ5doPWCJCIiIh1FACVMCVBi4iIWE8BUAlTErSIiIj1FACVsIx6YBoBEhGRiiE4OJjJkydb3YwsFACVMI+Lq8C0EaKIiIh1FACVMHdXJUGLiIhYTQFQCdMUmIiIlCWffPIJtWvXzlbV/frrr+fee+/ln3/+4YYbbiAwMJDKlSvTpUsXVqxYYVFr808BUAnTPkAiIgKAYUByvDW3HAqQ5ua2227j9OnT/PHHH85j586dY+nSpdx1113ExcUxdOhQVqxYwbZt2xg8eDDDhg3LtWJ8aaFq8CXMuQxeq8BERCq2lAvwRi1r3vvFE+Dhna9T/f39ueaaa/juu+/o378/AD/88AP+/v70798fV1dX2rVr5zz/P//5D/Pnz2fRokU8/vjjxdL8oqARoBLmSIJO0QiQiIiUEXfddRdz584lKSkJgG+//Zbbb78dV1dX4uPjef7552nZsiV+fn5UrlyZvXv3agRIslIOkIiIAODuZY7EWPXeBTBs2DDS09NZvHgxXbp0Yc2aNbz77rsAPPfccyxdupS3336bxo0bU6lSJW699VaSk5OLo+VFRgFQCfNQKQwREQGw2fI9DWW1SpUqcfPNN/Ptt99y8OBBmjZtSqdOnQBYs2YNo0aN4qabbgIgLi6OI0eOWNja/FEAVMJUCkNERMqiu+66i2HDhrFr1y7uvvtu5/HGjRszb948hg0bhs1m45VXXsm2Yqw0Ug5QCVMStIiIlEVXX301/v7+7Nu3jzvvvNN5/L333qNq1aqEhIQwbNgwBg8eTMeOHS1saf5oBKiEKQdIRETKIldXV06cyJ6zFBwczO+//57l2JgxY7I8Lo1TYhoBKmHOVWAKgERERCyjAKiEeagUhoiIiOUUAJUwxxRYkpKgRURELKMAqIRl5AApCVpERMQqCoBKmLt2ghYRqdCMAtThkuyK6vdnaQA0adIkunTpQpUqVQgICODGG29k3759l33dqlWr6NSpE56enjRs2JCPP/442zlz586lZcuW2O12WrZsyfz584ujCwVm1yowEZEKyd3dHYALFy5Y3JKyzbHDtKur6xVdx9Jl8KtWrWLMmDF06dKF1NRUXnrpJQYNGsTu3bvx9s55d8zDhw8zdOhQHnroIb755hv+/PNPHnvsMWrUqMEtt9wCwPr16xkxYgQTJ07kpptuYv78+QwfPpy1a9fSrVu3kuxiNu4Xd4JOVgAkIlKhuLq64ufnR1RUFABeXl7YbDaLW1W2pKenc+rUKby8vHBzu7IQxmaUorG4U6dOERAQwKpVq+jTp0+O57zwwgssWrSIPXv2OI+NHj2a7du3s379egBGjBhBbGwsv/zyi/Oca665hqpVqzJr1qxs10xKSnIWeAOIjY2lbt26xMTE4OPjU1TdA+Dnv0/w+Hfb6N7Qn9kP9yjSa4uISOlmGAaRkZFER0db3ZQyy8XFhQYNGuDh4ZHtudjYWHx9ffP1+V2qNkKMiYkBwN/fP9dz1q9fz6BBg7IcGzx4MNOnTyclJQV3d3fWr1/P008/ne2cyZMn53jNSZMmMWHChCtrfD6pFIaISMVls9kICgoiICCAlJQUq5tTJnl4eODicuUZPKUmADIMg3HjxtGrVy9at26d63mRkZEEBgZmORYYGEhqaiqnT58mKCgo13MiIyNzvOb48eMZN26c87FjBKg4eGgVmIhIhefq6nrFOSxyZUpNAPT444/z999/s3bt2suee+mcqWMWL/PxnM7Jba7Vbrdjt9sL2uRC0U7QIiIi1isVAdATTzzBokWLWL16NXXq1Mnz3Jo1a2YbyYmKisLNzY1q1arlec6lo0JWyCiGqgBIRETEKpYugzcMg8cff5x58+bx+++/06BBg8u+pkePHixfvjzLsWXLltG5c2fnEsPczgkJCSm6xheSu0phiIiIWM7SAGjMmDF88803fPfdd1SpUoXIyEgiIyNJSEhwnjN+/Hjuuece5+PRo0dz9OhRxo0bx549e/jiiy+YPn06zz77rPOcsWPHsmzZMt566y327t3LW2+9xYoVK3jqqadKsns5UhK0iIiI9SwNgD766CNiYmLo27cvQUFBztucOXOc50RERBAWFuZ83KBBA5YsWcLKlStp3749EydOZOrUqc49gABCQkKYPXs2X375JW3btmXGjBnMmTPH8j2AIHMOkJKgRURErFKq9gEqLQqyj0BBHT4dT7+3V1LF7saOCYOL9NoiIiIVWUE+v1ULrIQ5RoCUBC0iImIdBUAlTEnQIiIi1lMAVMIcGyGmG5CqIEhERMQSCoBKmGMVGCgRWkRExCoKgEpY5gBIeUAiIiLWUABUwhw5QKA8IBEREasoACphNpstU0FUBUAiIiJWUABkAedKsFTlAImIiFhBAZAF3J17AaVZ3BIREZGKSQGQBTLqgWkESERExAoKgCygHCARERFrKQCyQEZBVAVAIiIiVlAAZAFHErT2ARIREbGGAiALZOQAKQASERGxggIgC7g7c4CUBC0iImIFBUAWUBK0iIiItRQAWUBJ0CIiItZSAGQBZxK0coBEREQsoQDIAs4kaI0AiYiIWEIBkAUcpTBSNAIkIiJiCQVAFvDQKjARERFLKQCygIemwERERCylAMgC7m5mErRWgYmIiFhDAZAF3LUPkIiIiKUUAFnAQ6UwRERELKUAyAIqhSEiImItBUAW0D5AIiIi1lIAZAEP7QMkIiJiKQVAFnCUwlAStIiIiDUUAFnAMQKkKTARERFrKACygDMHKFVJ0CIiIlZQAGQB7QMkIiJiLQVAFnAmQSsAEhERsYQCIAt4KAlaRETEUpYGQKtXr2bYsGHUqlULm83GggUL8jx/1KhR2Gy2bLdWrVo5z5kxY0aO5yQmJhZzb/IvYx8g5QCJiIhYwdIAKD4+nnbt2jFt2rR8nT9lyhQiIiKct2PHjuHv789tt92W5TwfH58s50VERODp6VkcXSgUd5XCEBERsZSblW8+ZMgQhgwZku/zfX198fX1dT5esGAB586d47777styns1mo2bNmkXWzqKmJGgRERFrlekcoOnTpzNgwADq16+f5XhcXBz169enTp06XHfddWzbti3P6yQlJREbG5vlVpw83JQDJCIiYqUyGwBFRETwyy+/8OCDD2Y53rx5c2bMmMGiRYuYNWsWnp6e9OzZkwMHDuR6rUmTJjlHl3x9falbt26xtt3D1RVQKQwRERGrlNkAaMaMGfj5+XHjjTdmOd69e3fuvvtu2rVrR+/evfn+++9p2rQp77//fq7XGj9+PDExMc7bsWPHirXt7hdHgJQELSIiYg1Lc4AKyzAMvvjiC0aOHImHh0ee57q4uNClS5c8R4Dsdjt2u72om5mrjCTotBJ7TxEREclQJkeAVq1axcGDB3nggQcue65hGISGhhIUFFQCLcsfD2cStEaARERErGDpCFBcXBwHDx50Pj58+DChoaH4+/tTr149xo8fT3h4ODNnzszyuunTp9OtWzdat26d7ZoTJkyge/fuNGnShNjYWKZOnUpoaCgffPBBsfcnv7QKTERExFqWBkCbN2+mX79+zsfjxo0D4N5772XGjBlEREQQFhaW5TUxMTHMnTuXKVOm5HjN6OhoHn74YSIjI/H19aVDhw6sXr2arl27Fl9HCshRCiM13SA93cDFxWZxi0RERCoWm2EYmoe5RGxsLL6+vsTExODj41Pk1z+fmEKb15YBsO8/12B3cy3y9xAREaloCvL5XSZzgMo6xxQYaDdoERERKygAskDmAEiJ0CIiIiVPAZAFXF1suLpoN2gRERGrKACyiIcKooqIiFhGAZBF3F01AiQiImIVBUAWcSyFVw6QiIhIyVMAZBF3TYGJiIhYRgGQRZwBkKbARERESpwCIIsoB0hERMQ6CoAs4nFx92cFQCIiIiVPAZBFPDQCJCIiYhkFQBZRErSIiIh1FABZJCMJWsvgRURESpoCIIu4O/YB0giQiIhIiVMAZBFHKQzlAImIiJQ8BUAW8XBTErSIiIhVFABZxJEDlKQpMBERkRKnAMgi7q6qBSYiImIVBUAWcVcOkIiIiGUUAFnE7qYASERExCoKgCziqAWmYqgiIiIlTwGQRZxTYKnKARIRESlpCoAskrETdJrFLREREal4FABZxMNNI0AiIiJWUQBkEXdVgxcREbGMAiCLeDinwBQAiYiIlDQFQBZx1zJ4ERERyygAsogzCVqlMEREREqcAiCLeKgUhoiIiGUUAFnEXTlAIiIillEAZBEP5QCJiIhYRgGQRbQMXkRExDoKgCzioVIYIiIillEAZBHHMnjlAImIiJQ8BUAW0TJ4ERER61gaAK1evZphw4ZRq1YtbDYbCxYsyPP8lStXYrPZst327t2b5by5c+fSsmVL7HY7LVu2ZP78+cXYi8JRDpCIiIh1LA2A4uPjadeuHdOmTSvQ6/bt20dERITz1qRJE+dz69evZ8SIEYwcOZLt27czcuRIhg8fzsaNG4u6+VfErlVgIiIilnGz8s2HDBnCkCFDCvy6gIAA/Pz8cnxu8uTJDBw4kPHjxwMwfvx4Vq1axeTJk5k1a1aOr0lKSiIpKcn5ODY2tsBtKih3bYQoIiJimTKZA9ShQweCgoLo378/f/zxR5bn1q9fz6BBg7IcGzx4MOvWrcv1epMmTcLX19d5q1u3brG0OzPlAImIiFinTAVAQUFBfPrpp8ydO5d58+bRrFkz+vfvz+rVq53nREZGEhgYmOV1gYGBREZG5nrd8ePHExMT47wdO3as2PrgkHknaMPQKJCIiEhJsnQKrKCaNWtGs2bNnI979OjBsWPHePvtt+nTp4/zuM1my/I6wzCyHcvMbrdjt9uLvsF5cOwDBJCabjiTokVERKT4lakRoJx0796dAwcOOB/XrFkz22hPVFRUtlEhqzlKYYASoUVEREpamQ+Atm3bRlBQkPNxjx49WL58eZZzli1bRkhISEk3LU+ZR3y0G7SIiEjJsnQKLC4ujoMHDzofHz58mNDQUPz9/alXrx7jx48nPDycmTNnAuYKr+DgYFq1akVycjLffPMNc+fOZe7cuc5rjB07lj59+vDWW29xww03sHDhQlasWMHatWtLvH95cXWxYbOBYUBSWhrgbnWTREREKgxLA6DNmzfTr18/5+Nx48YBcO+99zJjxgwiIiIICwtzPp+cnMyzzz5LeHg4lSpVolWrVixevJihQ4c6zwkJCWH27Nm8/PLLvPLKKzRq1Ig5c+bQrVu3kutYPthsNtxdXUhOTddSeBERkRJmM7QEKZvY2Fh8fX2JiYnBx8en2N6n9atLiUtKZeWzfQmu7l1s7yMiIlIRFOTzu8znAJVlHtoNWkRExBIKgCzkSIRWRXgREZGSpQDIQiqHISIiYg0FQBbyUDkMERERSygAslDGCJACIBERkZKkAMhC7m7KARIREbGCAiALOabAUjQFJiIiUqIUAFlISdAiIiLWUABkIcc+QMlpaRa3REREpGJRAGQh5wiQiqGKiIiUKAVAFtJGiCIiItZQAGQhDzdXQMvgRURESpoCIAs5RoAUAImIiJQsBUAW0k7QIiIi1lAAZCFHEnSylsGLiIiUKAVAFlIpDBEREWsoALKQYx8g7QQtIiJSshQAWchDSdAiIiKWUABkIeUAiYiIWEMBkIXc3bQKTERExAoKgCykJGgRERFrKACykHKARERErKEAyELOVWAKgEREREpUoQKgr776isWLFzsfP//88/j5+RESEsLRo0eLrHHlnZKgRURErFGoAOiNN96gUqVKAKxfv55p06bx3//+l+rVq/P0008XaQPLM2cAlJpmcUtEREQqFrfCvOjYsWM0btwYgAULFnDrrbfy8MMP07NnT/r27VuU7SvXMpKgNQIkIiJSkgo1AlS5cmXOnDkDwLJlyxgwYAAAnp6eJCQkFF3ryjkPNyVBi4iIWKFQI0ADBw7kwQcfpEOHDuzfv59rr70WgF27dhEcHFyU7SvXPFxdAe0DJCIiUtIKNQL0wQcf0KNHD06dOsXcuXOpVq0aAFu2bOGOO+4o0gaWZ+5aBi8iImKJQo0A+fn5MW3atGzHJ0yYcMUNqkicO0ErABIRESlRhRoB+vXXX1m7dq3z8QcffED79u258847OXfuXJE1rrzzcCRBpyoJWkREpCQVKgB67rnniI2NBWDHjh0888wzDB06lEOHDjFu3LgibWB5plIYIiIi1ijUFNjhw4dp2bIlAHPnzuW6667jjTfeYOvWrQwdOrRIG1ieOXKANAUmIiJSsgo1AuTh4cGFCxcAWLFiBYMGDQLA39/fOTIkl6dSGCIiItYoVADUq1cvxo0bx8SJE9m0aZNzGfz+/fupU6dOvq+zevVqhg0bRq1atbDZbCxYsCDP8+fNm8fAgQOpUaMGPj4+9OjRg6VLl2Y5Z8aMGdhstmy3xMTEAvezuHloI0QRERFLFCoAmjZtGm5ubvz444989NFH1K5dG4BffvmFa665Jt/XiY+Pp127djmuKMvJ6tWrGThwIEuWLGHLli3069ePYcOGsW3btizn+fj4EBERkeXm6emZ/w6WEEcOUFq6QVq6giAREZGSUqgcoHr16vHzzz9nO/7ee+8V6DpDhgxhyJAh+T5/8uTJWR6/8cYbLFy4kJ9++okOHTo4j9tsNmrWrFmgtljBsQwezGkwVxdXC1sjIiJScRQqAAJIS0tjwYIF7NmzB5vNRosWLbjhhhtwdS25D/H09HTOnz+Pv79/luNxcXHUr1+ftLQ02rdvz8SJE7MESJdKSkoiKSnJ+bik8pgcSdBgJkJ7uisAEhERKQmFCoAOHjzI0KFDCQ8Pp1mzZhiGwf79+6lbty6LFy+mUaNGRd3OHL3zzjvEx8czfPhw57HmzZszY8YM2rRpQ2xsLFOmTKFnz55s376dJk2a5HidSZMmWbKJoyMHCCBF5TBERERKjM0wjAInnwwdOhTDMPj222+doy9nzpzh7rvvxsXFhcWLFxe8ITYb8+fP58Ybb8zX+bNmzeLBBx9k4cKFzmKsOUlPT6djx4706dOHqVOn5nhOTiNAdevWJSYmBh8fnwL1o6CavLSElDSDDeP7U9O39OUpiYiIlBWxsbH4+vrm6/O7UCNAq1atYsOGDVmmnqpVq8abb75Jz549C3PJApkzZw4PPPAAP/zwQ57BD4CLiwtdunThwIEDuZ5jt9ux2+1F3cx8cXd1ISUtTQVRRURESlChVoHZ7XbOnz+f7XhcXBweHh5X3Ki8zJo1i1GjRvHdd985l9/nxTAMQkNDCQoKKtZ2FZZjJZg2QxQRESk5hQqArrvuOh5++GE2btyIYRgYhsGGDRsYPXo0119/fb6vExcXR2hoKKGhoYC5w3RoaChhYWEAjB8/nnvuucd5/qxZs7jnnnt455136N69O5GRkURGRhITE+M8Z8KECSxdupRDhw4RGhrKAw88QGhoKKNHjy5MV4udymGIiEiZsPpt2PyF1a0oMoUKgKZOnUqjRo3o0aMHnp6eeHp6EhISQuPGjbMtVc/L5s2b6dChg3OF1rhx4+jQoQP//ve/AYiIiHAGQwCffPIJqampjBkzhqCgIOdt7NixznOio6N5+OGHadGiBYMGDSI8PJzVq1fTtWvXwnS12Nm1G7SIiJR2sRHw+0T45QUoeOpwqVSoJGiHgwcPsmfPHgzDoGXLljRu3Lgo22aZgiRRXam+//uDI2cuMPfRHnSq73/5F4iIiJS0iL/hk97m/Zciwb2Ste3JRbEkQV+uyvvKlSud99999938XrbCc+YApZaPiFpERMqhhLMZ95MvlNoAqCDyHQBdWm4iNzab7fIniZOSoEVEpNS7kCkASokHqlnWlKKS7wDojz/+KM52VFiOchjaCFFEREqtS0eAyoFCJUFL0fG4WA5DSdAiIlJqXTiXcT9FAZAUAQ83TYGJiEgpl6AASIpYxj5ASoIWEZFSSlNgUtQyVoFpBEhEREqpbEnQZZ8CIIt5aCdoEREp7TQCJEXNXUnQIiJS2mUZAVIAJEVASdAiIlLqJSgAkiLmTILWTtAiIlIapadBQnTGY02BSVHI2Ak6zeKWiIiI5CAxBsj0JV1J0FIUPNy0DF5EREqxzHsAgUaApGg4kqC1DF5EREqlzAnQoBwgKRruWgYvIiKlWcIlAVCypsCkCGRMgSkAEhGRUkgjQFIcPFQKQ0RESjPHCJCLu/kzJcG6thQhBUAWUykMEREp1RwjQL61zZ+aApOikLEMXgGQiIiUQo5VYL51zZ+aApOioFIYIiJSqjmmwHwcI0AKgKQIKAlaRERKNecUWB3zpzZClKLgoVIYIiJSmiVcEgBpBEiKgiMHKEkjQCIiUhpdcOQAXQyA0pLM+mBlnAIgi7k7psC0CkxEREqjS0eAoFwkQisAspiSoEVEpNRKScwIdqoEAeZnVnmYBlMAZDG7kqBFRKS0ciyBt7mCpy94eJuPy0EitAIgi7lrJ2gRESmtHNNflaqCzQbuXuZjjQDJlXImQSsHSEREShvHEngvf/OneyXzp3KA5EqpGryIiJRazhGgiwGQYwqsHJTDUABkMQ8FQCIiUlplGwG6OAWmESC5Uu5uWgUmIiKlVOYcIAAPRwBU9ivCKwCymEemJGjDUCK0iIiUIhcuCYDcNQUmRcSxESJoJZiIiJQyCdHmT8cUmIemwKSIOEaAAJI1DSYiIqXJpUnQzmXwGgGSK+SeKQBSOQwRESlVlARdPFavXs2wYcOoVasWNpuNBQsWXPY1q1atolOnTnh6etKwYUM+/vjjbOfMnTuXli1bYrfbadmyJfPnzy+G1hcNVxcbLhd3FlcitIiIlCrZlsFrI8QiER8fT7t27Zg2bVq+zj98+DBDhw6ld+/ebNu2jRdffJEnn3ySuXPnOs9Zv349I0aMYOTIkWzfvp2RI0cyfPhwNm7cWFzduGIeF/OANAUmIiKlSrYRoPJTCsPNyjcfMmQIQ4YMyff5H3/8MfXq1WPy5MkAtGjRgs2bN/P2229zyy23ADB58mQGDhzI+PHjARg/fjyrVq1i8uTJzJo1q8j7UBTcXV1ITElXErSIiJQehpFRC+zSESAtgy9Z69evZ9CgQVmODR48mM2bN5OSkpLnOevWrcv1uklJScTGxma5lSRHInSycoBERKS0SIwBI82871wGrykwS0RGRhIYGJjlWGBgIKmpqZw+fTrPcyIjI3O97qRJk/D19XXe6tatW/SNz4PKYYiISKnjGP1x9wJ3T/O+qsFbx2azZXns2Dww8/Gczrn0WGbjx48nJibGeTt27FgRtvjyHLtBKwdIRERKjUsToKFcjQBZmgNUUDVr1sw2khMVFYWbmxvVqlXL85xLR4Uys9vt2O32om9wPjl3g9YUmIiIlBYXLo4AeVXNOKZq8Nbo0aMHy5cvz3Js2bJldO7cGXd39zzPCQkJKbF2FpR7pnIYIiIipUJOI0DlqBq8pSNAcXFxHDx40Pn48OHDhIaG4u/vT7169Rg/fjzh4eHMnDkTgNGjRzNt2jTGjRvHQw89xPr165k+fXqW1V1jx46lT58+vPXWW9xwww0sXLiQFStWsHbt2hLvX345lsErB0hEREqNS5fAgzZCLCqbN2+mQ4cOdOjQAYBx48bRoUMH/v3vfwMQERFBWFiY8/wGDRqwZMkSVq5cSfv27Zk4cSJTp051LoEHCAkJYfbs2Xz55Ze0bduWGTNmMGfOHLp161aynSsAxwhQkqbARESktMhrBKgcLIO3dASob9++eVZAnzFjRrZjV111FVu3bs3zurfeeiu33nrrlTavxLi7mknQGgESEZFS49JK8JC1FphhQB4LjEq7MpUDVF5pGbyIiJQ6jmXwmafAHBshGmmQllzybSpCCoBKAbtygEREpLTJaxk8lPlEaAVApYBjBChZq8BERKS0yCkJ2tUdXMxV12U9EVoBUCngrlIYIiJS2uQ0AgTlpiK8AqBSQDlAIiJS6lzIIQcIyk1FeAVApYDHxVIY2glaRERKhdRkSD5v3s+8CgzKTUV4BUClgIdGgEREpDRJjL54xwaevlmfKyf1wBQAlQJKghYRkVLFuQeQH7i4Zn2unFSEVwBUCri7KQlaRERKkdwSoEEjQFJ0lAQtIiKlSk5L4B2cFeE1AiRXyEOlMEREpDTJawTIWRFeI0ByhTJygBQAiYhIKZDnCFD5qAivAMgKl0TNHs5SGEqCFhGRUiA/I0AKgCTfDq+GKe1h1ogsh505QEqCFhGR0sBZCLVq9ufKSRK0m9UNqFC8A+DcYTgfAalJ4GYHMvYB0hSYiIiUCs5l8DkEQB6aApOCqtEMvGtAaiKEb3EedndTErSIiJQijhGgHJfBO5KgtQpM8stmg+Be5v0ja52HVQxVRERKlXwtg9cIkBSEIwA6vNp5SKUwRESkVMkzCbp85AApACppwb3Nn8f/gpREIGMnaK0CE8ulpcJXw+Cnp6xuiYhYxTAuMwKkUhhSGNWbZssD8tAUmJQWp/aYo5NbZkBaitWtERErJMdB+sV//3mNAKkavBRIDnlAKoUhpUbsiYt3DHO1oohUPI4EaDfPjGAnM3ftBC2F5QyA1gDgfrEUhpbBi+Vijud8X0QqjryWwEOmESBNgUlBBfcxf17MA8rYCVoBkFgsNjzjfkx47ueJSPmVVwI0lJuNEBUAWaF6E3NTxNRECN+caRWYkqDFYpmDnliNAIlUSHklQENGKYzUBEgvu1/cFQBZ4ZI8IO0DJKVGlhEgBUAiFZJzE8RcpsAc+wBBmd4LSAGQVTIHQG4qhSGlRJYcIE2BiVRIlxsBcsscAJXdlWAKgKzi2A/o2CbcjSTAzAEyDE2DiUUMI9MqMDQFJlJRXS4HyMUlIw+oDCdCKwCySvUmUDkQ0pKodHIbYH7+pKUrABKLXDgDaUkZjzUFJlIxOSvB5xIAQblIhFYAZJVMeUD28PXOw0qEFss4Ah6PyubPhHNl+j83ESmkyy2Dh3JREV4BkJUuBkBuYRmFUZUHJJZxJEBXb5oRBMUqD0ikwrncFBiUi4rwCoCsdDEPyHZ8M3aSAa0EEws5kp59a4NvnYvHjlnXHhGxxuWSoEEjQHKFqjWGyoHY0pLo4vYPAIkpaRY3SiosR9KzT23zBloJJlIR5WsEyJEDpBEgKYxMeUCDvQ8CsObAaStbJBWZI9jxqW2OAoGmwEQqmrRUSIwx7+cnCVrL4KXQLgZAAyrtB2DOX2FWtkYqMscSeN/a4FvXvK8pMJGKJTE6476nX+7naQrsyn344Yc0aNAAT09POnXqxJo1a3I9d9SoUdhstmy3Vq1aOc+ZMWNGjuckJiaWRHcK7mJdsJrnd+LtmsL24zHsPhFrcaOkQnJOgdXRFJhIReVYAu/pC65uuZ+nJOgrM2fOHJ566ileeukltm3bRu/evRkyZAhhYTmPgkyZMoWIiAjn7dixY/j7+3PbbbdlOc/HxyfLeREREXh6epZElwquWiOoXBNbWhIPBZ8B4PvN+tYtJSw9HWIjzPuZk6A1BSZSsVzIR/4PaAToSr377rs88MADPPjgg7Ro0YLJkydTt25dPvrooxzP9/X1pWbNms7b5s2bOXfuHPfdd1+W82w2W5bzatasWRLdKZxMeUA3VT0EwPxt4UqGlpIVHwXpKWBzgco1M60CO27u0CkiFUNCPvYAAm2EeCWSk5PZsmULgwYNynJ80KBBrFu3Ll/XmD59OgMGDKB+/fpZjsfFxVG/fn3q1KnDddddx7Zt2/K8TlJSErGxsVluJepiAFQvdiu1/SoRk5DC0l2RJdsGqdgcU12Va5rD3j61zMcpFzKGxEWk/Du00vzp+D8gN46K8CqFUXCnT58mLS2NwMDALMcDAwOJjLz8h39ERAS//PILDz74YJbjzZs3Z8aMGSxatIhZs2bh6elJz549OXDgQK7XmjRpEr6+vs5b3bp1C9epwnLuB/QXb9X8jQDOMecvTYNJCXLk/zhWf7lXAq/qF5/TNJhIhRB9DDZ/Yd7v+lDe5zoqwmsEqPBsNluWx4ZhZDuWkxkzZuDn58eNN96Y5Xj37t25++67adeuHb179+b777+nadOmvP/++7lea/z48cTExDhvx46VcPBRrREEtIT0FHodmcZ6++M8FPY8pzbMhtSky79e5EplXgLv4AiGVBNMpGJY/T9ISza/lDe4Ku9z3ct+DlAeKd7Fq3r16ri6umYb7YmKiso2KnQpwzD44osvGDlyJB4eHnme6+LiQpcuXfIcAbLb7djt9vw3vqjZbPDAMtg1H7Z9i+uxDfRz3Q6/PgIrX4C2w6HLg1CjmXVtvFRiDMSfNnNGXFzB5goubuZ9j8rgXkqTziVnjlEeR+4PmKvBIrYrABKpCM78A9u+Me9f/bL5uZQX5xSYAqAC8/DwoFOnTixfvpybbrrJeXz58uXccMMNeb521apVHDx4kAceeOCy72MYBqGhobRp0+aK21ys7FWg4z3Q8R5WrVvPjiUfcZvbWgITz8CmT81bw37Q/VFoPBBcLBq8O3cU/pxi/kNJy2V0ys0TWgyDDneby/ytaqvkX2xOI0BaCSZSYax8E4w08/OlXvfLn18OkqAtC4AAxo0bx8iRI+ncuTM9evTg008/JSwsjNGjRwPm1FR4eDgzZ87M8rrp06fTrVs3Wrdune2aEyZMoHv37jRp0oTY2FimTp1KaGgoH3zwQYn0qSj06NqNcb/F8W78bfw4KJmOUfNg3xI49Id5828IXR+B9neagVP8KXPuNibM/LYec/zi3gyZVu847npXh9Y3Q822l4/wMzu1D9a+B39/b/4jAXOkxzDMx+lp5k8jHVITYccP5s23HnS4y2yrX72i+hVJUctcB8xBU2AiFUPUHvP/azBHf/LDuQy+7CZBWxoAjRgxgjNnzvD6668TERFB69atWbJkiXNVV0RERLY9gWJiYpg7dy5TpkzJ8ZrR0dE8/PDDREZG4uvrS4cOHVi9ejVdu3Yt9v4UFQ83F27pVIdPVx/iw2P1+fzeb82Rl02fwtav4ewh+PUFWPGaGXDkNhKTmz8nQ43m0HaEOb2Wedojs9QkiPgb1k2FPT/hjKIa9oPez5ir1y4NogwDTmwzR4h2/GgGZSsnmd8uGvWDYVMUCJVGOY0AaTNEkYrhj/8DDGhxPdRqn7/XODdCLLsjQDbD0CYfl4qNjcXX15eYmBh8fHwsacPBqDgGvLsKVxcb6/51NYE+F3NqkuJIC51FwtoPqXze3DfIwIatShD41TVLGPjWAU9Huy8GKDabGZxEbId9v2QKmi7uQ9RsiJnXc+4oRB81f56PIMsoUvProNc4qNMpf51ISYA9P8O2r+HwKvNY3W5w36+aFitN0lLhPzXMYHrcXvAJMo+HbYQvBpkB61M7rG2jSH5cOGuOVtfrXrAR7orsxDb4tC9gg8fWQ0CL/L0uYjt80geqBMEze4uzhQVSkM9vS0eAJHeNAyrTuX5VNh89x49bjjOmX2OiLyQz+6+TzFzXkIiY12lqO048ntiq1OLhns0Z3rkOdjfXy188MQZ2L4Ttc+DoWjiyxrzlxN3LDHx6j8v/PwznaytB29vMW9Re+Lw/HNsIf30O3R4u2LWk+MRFmsGPixtUDsg47iyIesKc4nTJx98tESvNHw0HlsL9S/OXxyLw+/+ZP9sOL9j/8coBkuI0oktdNh89x6xNYYRHJzBv63ESU9IBqObtSefWvVi++yRRsUm8smAnH/x+kEf7NmJEl7p4uufxYeXp60y4JjrMzOs5vhmqBIJfffMbf9VgYuxBfLEtjvb1q9K3Rg2u6PtUQHMY8BoseRZ+mwDNrtFUWGnhKIJapVbWIKdyTXOVX3oqxEVljAyJlFbhm82fJ3cpAMqPsA1wcLm5iveqFwr2Wi2Dl+J0bdsgJvy0m+PnEvhuo5kL1SLIh/t7BjOsXS083V155bqWzPnrGB+t/IfI2EReXbSLD1cepGuDalxISiU+OZULyWnEJ5k/61StxFu3tKVhjcrmm/jVgz7PZnvv03FJ3P35RvZGngegS3BVnr+mOV2CL1MfJi+dHzDzgo5tgJ+fhrt+LL3D1Cvfgq0zYeR8qNHU6tYUr5hLNkF0cHUzg6LY42aOkAIgKc3iz8AFs56iVi7mg2HAbxPN+x3uNvejKwhHEnR6CqSlgKt70bavBCgRoxTz8nDjwd4NsNlgcKtAZj/cnSVP9uK2zhkjPJ7urtwbEsyq5/sy8cbW1PL15GRsEj9tP8Fve6PYcOgsfx+P4Z9T8UTEJPLXkXPc9OE6Nhw6k+v7noxN5PZPN7A38jx+Xu7Y3Vz468g5bvt4Pfd9uYldJ2IK1yEXF7hhGrja4eAKc+SpNEpLgfUfmB/8a9+1ujXFL6cEaAfnSjDtTC6l3On9Gfcdo5qSu0MrzRQIVw+46vmCv96RBA1ltiK8RoBKubH9mzC2f5PL7o5td3NlZPf6DO9ch193RnI6LpnKdle8PNzwvvjT3dXGfxbvYVtYNCOnb+StW9pyc8esK8DCoxO467MNHDlzgSBfT759sBteHm5M+e0A328+xh/7TvHHvlMMa1eLZwY2Jbi6dy4tykX1JuY/tt8nmivZGl0NlWsU9NeSM8OAU3uherMrS7I+sgaSLgZ5O+fCwNez5saUN85doHOo/aOVYFJWnN6XcV9bN+TNMOC31837ne/PfSVwXtw8zLzB9FRzGqySX5E2sSRoBKiUs9ls+SoN4mB3c+WG9rV5oFcDRnSpx7B2tbi6eSDdG1ajU31/Zj3UnWvbBJGSZjDu++28u3w/joWAYWcuMPzj9Rw5c4E6VSvx/SM9aFijMjV9PZl0cxtWjLuKYe3MD8mftp9g4Hur+L/Fu4lJSClYp3qOhcA2ZpHNXws475yXZS/Dh91hfe5lT/Jl7+KM+2nJsPnLK7teaeesA5bDf4KZq8KLlGanNAKUb7sXwomt5ihO72cKf50yvhReAVAF4+nuyvt3dOCxvuZ879TfDvDUnFD2RMQy/JP1hEcn0KC6N98/0oO6/l5ZXtugujfv39GBxU/24qqmNUhJM/hszWH6vb2SbzYcJTUtPX+NcHWHG943E2x3zoW9S668Y0f+hPXTzPtbZpjfcAojPT2jPW2Gmz83T4fU5CtuYqmVUx0wB+du0AqApJTLMgUWXvj/A8q7tFRzBB4g5PErG90u45shKgCqgFxcbDx/TXP+e0tb3FxsLAw9wdCpa4iMTaRJQGXmPNydWn6Vcn19q1q+fHV/V2bc14XGAZU5G5/Mywt2cu3Utfx58HT+GlGrA4Q8Yd5fPM5cml9YyfGw8LGMx2cPmXtbFEbENjh/wtzl+rp3zZVQcSdh94LCt6+0i81hF2gHTYFJWZF5Ciw10Rxhluy2fQ1nDoJXNejx+JVdq4xXhFcAVIEN71KXr+7vShVPNwwDWgb5MPvh7gT45K+Qad9mAfwytjcTrm+Fn5c7+06e567PN/LgV3/lL1G673izrMf5CPj+3sJ/yK54Dc4dMT+smwwyj+34sXDXckx/NR5glhnp8qD5eOPHhbteaZeabC5xB7P46aU0BSZlQfIFsxwQmLUIQX9nc5J8wdyVH6DPc5k2zC0k97JdEFUBUAXXs3F1fnq8F/++riWzHupOtcr2Ar3e3dWFe0OCWflsX0aFBOPqYmPFniiunbqWB7/azI7jeQRC7pXg+mng4m7WOPugK2z42Nx0L78OrzFLhABc/z50us+8v3Nuwa7j4AiAml9n/uw0ylwlEb4Fjv1V8OuVdo7dvl3tZp24SzkCoPgoszSKSGl05iBgQCV/qH5x2wothc9u48fmxqd+9czk5yvlUbb3AlIAJARX9+b+Xg3w9Sr8Pg5+Xh68dn0rlj7Vh+vb1cJmgxV7TjJs2loemPEX249F5/LmPeGR1VCnKyTHmUnRnw8wa5BdTlIcLBxj3u94LzTub47cePqZ/8iP/lmwTpw+aK4ic3GDJgPNY5VrQJvbzPvlcRQoNtMKsJyS7b2qZXyjLmhiaWoyrPqvuWW+SHFy5P9Ub5opb00BUBYXzsLayeb9fi+BW8G+7OaojO8GrQBIilTjgMpMvaMDy5++ips61MbFBr/tjeKGD/7kvi83EXU+MfuLAluaW9df+y7Yfc3VCZ/2NVd15bW/xIrXzLplvnVh0H/MY24e0PJ6876junF+7bs4+hPcO+uSzm6PmD93Lyh/q0vySoAGMyjyKWRV+NBvzCKLPz1V6OaJ5IsjAKrRVHlruVn7nrm9R0CrjC91V8rDMQWmJGgRp8YBlXlvRHtWjLuKWzrWwdXFxh/7TvHivFyKarq4QJcH4PFN0OomMNJg3fvwXmtz1+gjf5ortBwOr4a/PjPvX/9+1rlsxz/u3QsLNm3jnP66NuvxoHZQL8Tc72LzF/m/XlkQm8su0Jk5a4IV8APlwHLzZ0SoElKleJ26mABdvVnGflbl7cvKlYg5Dhs/Me8PeLXo6vppBEgkdw1rVOad4e1YOKYnbhfzg1bui8r9BVVqwm0z4M4fzHnqhLNm0DFjKLzXCpa+BEfXZUx9dboPGvXLeo36Pc0KxYkx5o7T+XH+JBzbZN5vNjT7845RoM1fQkoOo1hl1eVGgMAcYYOCjQClJsGhVeZ9I938MxMpLqcPmD81BZazlZMgLcn8IudYKFIUlAMkcnmta/syKiQYgNd/3k1y6mX2DGo6CJ7YBnfPg/Z3m1Nj50+Ye/18OcQs4upbDwZNzP5aF1dodbN5P7+rwfYtAQyo1THn0ZDm15mrpC6cNhOsi1NirFmL7Ozh4n0fyHsJvENhpsDC1mcdFj+8puBtE8mP9LSLSdBcnAJzjAApAAIgai+EfmfeHzihaOsvOkeANAUmkqcnBzShemUPDp2KZ+b6I5d/gaubmdh84wfw3AG4/TtofYv5j87F3awrZq+S82vb3Gr+3PcLJJ2//Hs5pr9aXJd7W7o6lsR/VLybrP02AVa+AfNHF997ODiToPPYCr8wU2CO6S/vi2VODq8ueNtE8uPcEXN0w83THK10BOyxJ7QZIph5eEa6+SWubteivbazInxC0V63hCgAkhLj4+nO84ObAzBlxQFOnS9Afo6b3czNufULeO4gPL0LGl6V+/m1OoB/I0hNuPxO04mxcPjidE3zXAIgMFeauVWCyB2w56fi+c819oRZhR7g2IaMabniEpOPESDnXkAFCIAcU499LhZZjNoF8fncJFOkIBzTX9WamKO/jhGg1ERz5VNFlp6W8WWkz3NFf33tBC2Sf7d2qkPbOr6cT0rlf0v3Fu4iHt5QJTDvc2y2jGTonZeZBju4wqz5Va1xxh4iOfHyh7YXy2N8PxI+7g2bPruyXawv9edUsy3Ox1OK7tqXSkk0p/Qg7xwgnwJuhhh9zNxOwOZijsQFtDKPH9E0mBQDxw7QNS7+23WzZ4w8VvQSLmf+Mb8EuntBzTZFf33VAhPJPxcXG68OMz8Qf9hyPPf9gYqCYxrs4G95jz5kXv11ufnxga9DuzvMjQNP7oAlz8LbzWDBGHOjxCsZFYqLgi0XC69e82ZG204fLPw18+KY0nKrBJWq5n6eY3QoKSZ/04mO0Z86XcygsUFv87HygKQ4nMq0B5CDlsKbTl5cdRvQsuhWfmWmJGiRgulUvyo3d6iNYcBrP+0iPT170JCYksai7SdYGBrO+cQCVpt3qN7EXMJupOVeyys1GQ4sM+/nNf3lUMkPbvoYntkL17wFNZqb37BCv4HpA+CHUVmX6xfEuvfNYfvanaDbaGh6DWBkFHktapkToPMK/OxVwNPXvJ+fDxRHANT44maSDfqYP5UHJMXhdB4BUEVPhI7caf6s2bp4rq8kaJGCe2FIc7w8XNkWFs2C0Iz/pI6eief/Fu+m2xu/8eSsbYydHUqn/6xg9NdbWLIjgsSUApa3cEyD7chl5daRNZAUC94BULtz/q/r5Q/dR8NjG8xNHNvdYSZm714A6woxbRV/Bv6abt7v87wZkIQ8aT4O/Q7iThX8mpeTnyXwDvmdBktNhkMrzfuN+5s/64cANjhzAGIjCtNSkZwZRsYUWOYAqLB7V5U3kRdHgAKLKQByboSoESCRfAv08eTxqxsD8OYve/l1ZwT3frGJq/63ks/WHCYmIYU6VSvRqIY3yanp/Lorkse+3Urn/6xg3JxQVu8/hZGf6aZWNwM2CFuXUSwxM+f011BzM8aCstmgXndzVOjad8xjv02Eo+sLdp0NH5qJhDXbQtPB5rH6IeZoUFpSRr2zouQcAcpjBZiD8wPlMgHQsQ1mSRPvGhDU3jxWqao5EgfKA5KiFX/KzMGzuZg5fA7aDNF00jEC1LZ4rl/Gq8G7Wd0Aqbge6NWAOX8d4+iZC4z+ZitgxhNXNa3ByO716dssABcb7I6IZdH2E/y8PYLw6ATmbQtn3rZwujbw59/XtaR1bd/c38S3trkx4tG18Ou/zGWy5yMg7qT50xEU5Wf663I63mN+wO/4AeY+AKPXmiNFl5MQnRHg9HkuYzrKMQr0w73mrte9nsr4xlUUYgswApTflWCOFSeN+mcNKBv0NneEPrw6I5Fc5Eo5doD2qw/unhnHfQqxcrG8iT9zsdgxZrmh4qBq8CKFY3dz5bXrW+FiA99K7jzUuwErn+3LjPu60r9FIK4uNmw2G61q+TJ+SAvWPN+PH0f3YGT3+tjdXNh0+CzDpq3luR+2ExWbx+7MjmTovT+be/jsXmBu1HfuiJkfVK1xRp7KlbDZ4Lr3zOvFhpv7+OQnH2jjJ+Y0XEDL7IFYi2FQtYFZSmLbt1fexsycU2C1Ln9ufjdDPPib+dNRTNahwcUtCzQCJEUpp+kv0BQYZCRAV22Q+35pV6qMJ0FrBEgs1a9ZAOv+1R8/L3c83fNepeDiYqNzsD+dg/0Z3bcRb/2yl0XbT/DDluMs3hHBY30b8WDvhni6u5KWbnA6LomImEROuvWlfp3b8HVNolpQfTz8akPlQLNcRpVAc1TI1b1oOmSvYpby+Kw/HFgK69+HnmNzPz8x1pz+Auj9TPZpOBdX6DHGXG22fhp0vt/clPFScVFmkFS9af53ei3QFJijvEAeAVBMuLnfj80FGl2d9bl63cHmagad0WFmmRORK+XYA6jGJQFQ5ikwwyja3Y/LCkf+T3ElQEOZrwWmAEgsV9PX8/InXaK2XyWm3tGBe0OCmfjzbkKPRfP2sv3MWHcUu5sLJ2MTSc2yuuwmANwO2Ghf149eTarTq3J12vn64e5axAOhNdvAkLfg56dgxQSo2x3qdcv53L8+g8RocxO3VjflfE77u8xaPtFHYc8iaH1zxnMXzsKad8wptLRkc8+dzveZ00yeeUwNQsZoTlFNgTlWf9XulH3qz17FPH58k7kcvsNdl39Pkcs5lcsIUJWLAVBaElw4A97VS7ZdpUFkMef/QNYk6DIYaGoKTMq0TvWrMu/REKbc3p5avp6cjksiPDqB1HQDFxsE+XrSsZ4fg1sFUr+aF6npBpuPnmPyigPc+vF6Ory+nEe/2cIfe6NIy2E5fuEbNsos22GkwY/357wjbXI8rP/AvN/n2dz36fDwgi4PmffXTTX/o0lJgLWTYWp7c2QoLRlc3MwRmCXPwjvNYdETEL4152smx5uBF+S9C7RD5mXFuSWfH7yY/9N4QM7PO/cD0nJ4KSLOIqjNsh538zBXdkLBatiVJ44E6OJaAQYZI0AYZbIchkaApMxzcbFxQ/vaDGpZk01HzlLZ7kaQrycBVey4XTK6c+zsBf48eJq1B0/z58HTnLuQwi87I/llZyQ1fTy5rXMdhneuS11/r1zeLZ9sNrhuMpwIhbP/wFfXg38DSE+FtBQzYLlwxrxVbQCtb837el0fgj8nw4ltsOJVc1m/YzoqsLVZ5LB2J9g+BzZ/YeZGbJ1p3mq2hYZ9zTpAdbqa036OkRyPKpcfKYJLygvk8I06LSWj+nvjS/J/HIJ7m6NVR9aUyW+LUsokxWX8G6jeJPvzvrUhPsoM2mu1L9GmWS41OWN0rCSmwMAcBfK4wv83S5gCICk3Knm4clXTGnmeU9ffi9u71uP2rvVITzfYdSKWBaHhzNt6nMjYRN7//SDv/36Qno2rcUfXegxtHYSLSyE/qD19zHygzweYCYmOpMRL9Xku57yezLyrm1Nhm6dnlMfwqQNXv0xSy1t4eeEewn7by7Q776NGt0fMJO/NX8DuhRD5t3lz8KufkYOTn9EfMMsLVK4JcZFmccVr3jSPORzbaCZye1Uz67DlpG43cPUwP5DOHoJqjfL33iI5cWyA6F0j59WWPrXNLwwVcSn86X2QnmJ+ufGtW3zv4+JiFqFNTTRHlcvYVKMCIKmwXFxstKnjS5s6vjx/TTNW7I5i9l9hF0eHzvDnwTNc3Tycd25rR1Vvj8K9SVBbGLUYjv9lJlq7upsbJjrue1UzR0byI+Rxc4m9zWYmTHd9hCSbO49+s5Xf90YBMObbrXz7UDfc64eY+whd8xbs/9XMvTm2CaL2mLlE0UfNa+YnAdqh9zj45XkzsArfCrd9Cf4Nzecc+T+XLn/PzMPLLI9x9E9zGkwBkFyJ3Ka/HPK7crE8cm6A2Kb4R1rdvcwASFNgImWT3c2Va9sGcW3bII6fu8Ccv47xyepD/L43imunrmHaXR3pWC+PellASlo6F5LTMAwDw4B0wyDdAMO3DYZvRiHCzCk0ldxd8c3vf1D+DWHsdnPkxcPcIHLMt1v4fW8UdjcX3F1d2HTkLBN/3s3rN1wc9vauZiYcO5KOE2MgfItZt+z0fuj6cP5/Sd0eMafr5j9i7unzyVVw/fvQ6kY4cDEAunT5+6Ua9MkIgDrfl//3FrmUcwl8DtNfkGkpfAUcASruEhiZeXhDwtkyWRFeAZDIJepU9eKZQc24pnVNxny7lSNnLjD84/W8cE1zHuzdAFumgMUwDDYePsv3m49dLNVRsDpgNhv0aWJu/NiveQCul5tuuzjUn5yazpjvtrJijxn8TL+3C4kpaTw4czMz1x+ldS1fhnfJYejb09dcon7pMvX8ajoIRq+BHx8wd33+4V44cNfF6T3b5a8b3BuYpDwguXKOKbAalxkBqoh7ATmm24szAdqhDC+F1yowkVy0quXLT0/04rq2QaSmG/zfkj08NHMz0ReSORmbyAd/HKTf2yu5/dMNzNsanmPwY7OBiw1cXWy4Zbq5u5o3w4BV+0/x4MzN9PnvH3zwx0FOnU/Ks10paek8MWsry3efxMPNhc/u6UyvJtUZ0DKQcQPN5cAvL9jJtrBzxfJ7wbcOjPoZej1tPg69uEFjrQ7ZcgAuJKdmfW2dzmb1+fhTcGpv8bRPKoacqsBnVlEDIMMo4RGgsrsZokaARPJQxdOd9+/oQLeG1Zj4025W7Imi39sriUlIwbFq3tvDleva1mJ4l7q0ru2Dq82Gi82GzUaW0aKcHD0Tz3cbw5iz+Rjh0Qn8b+k+Jq/YzzWtg+je0J8G1bxpUMObwCqeuLjYSElL58lZ21i66yQeri58OrITfTIlfj/erzG7TsSwdNdJRn+zhZ8e70WAT8H3WbosV3cY8BrUCzGnxBLOktJ4MKFHzrIt7Byhx6LZFhZNREwinepX5d3h7ahfzducvqvXzSyYengNBLQo+rZJ+ZeWYq6uhDwCoEybIaanF67WX1kUe8KckrK5Qo0S+PflKIdRBivCKwASuQybzcbI7vXpUNePMd9t5egZ85tOl+Cq3Na5Lte2CcLbXrh/SvWreTN+aAueHtiUJTsi+HrDUbaFRfPT9hP8tD0jd8HT3YXgat64udrYGR6Lh6sLn4zsRN9mAVmu5+Ji453h7Tn0wZ8ciIpj9DdbmPVwd+xuee+yXWhNB7HtuiWs/eU7PlnRlLj07EVgtxw9x5Apa3h1WEuGd66LrUEfMwA6shq6FSAHScTh3BFzSwl379w38vSpBdgytpyonPcK0XLDsf9P9aZZ66MVlzI8AmR5SPzhhx/SoEEDPD096dSpE2vW5F4raOXKldhstmy3vXuzDqXPnTuXli1bYrfbadmyJfPnzy/ubkgF0Lq2Lz8/0Yv/3dqW3565ih9GhzC8c91CBz+Zebq7cnPHOsx/rCc/P9GLh/s05OrmATSo7o2bi43ElHT2Rp5nZ3gs7q42Prq7I/2aB+R4rcp2Nz67pzM+nm5sDYvmtUW7MHLbvPAKHTt7gVE/HuOd092JS7dTo4qdQS0DeeGa5sx6qDsrxvWhWwN/LiSn8cLcHTzy9RZiavYwX3xoFZw7WiztknLOuQN049xHdlzdzZI3kHcJl/KmJEpgZOaoCK9VYAUzZ84cnnrqKT788EN69uzJJ598wpAhQ9i9ezf16uVeK2jfvn34+Pg4H9eokRHZr1+/nhEjRjBx4kRuuukm5s+fz/Dhw1m7di3duuVSjkAkn6p4unNb52LcVwMz0Mpc4T4lLZ3j5xI4cjqeI2fiaVvHj071816RFlzdm6l3dOC+GX8xa9Mxft8bRY+G1ejRqBohjapn2ejRMAzCoxPYdSKWXeEx7I6IpXlNH8YNbJrnHkiJKWk8+u0WYhJSaFfHlw/v7kQtX89s037fPdSdz9Yc4p1l+1i2+yR/h7mxwrcZlWP2wVfD4P5f81eQNRd7I2Nxc7HRoHrlyyeRS/ngXAGWSwK0g08tc++qmPDc96cqbxwjQDXb5H1eUSnDU2A2o7i+GuZDt27d6NixIx999JHzWIsWLbjxxhuZNGlStvNXrlxJv379OHfuHH5+fjlec8SIEcTGxvLLL784j11zzTVUrVqVWbNm5atdsbGx+Pr6EhMTkyXQEilrvl5/hP8s3kNSatYE7dp+legSXJXTccnsPBFD9IWUbK+9uWNt/ndru1yDihd+/Js5m49R1cudn5/sTW2/Snm2ZWd4DE/PCeVAVByBnOUXnzfwTz5hDtWPWlKoKYoVu0/y4MzNgDlN2KymDy2DfGhZy/zZqpbPZYvsXinDMC6b6yVFbP5o2D4Lrn7Z3Eg0N3Puhj0/wZD/VZzp1vc7wZmDcPc8aNy/+N9v8TPw1+dw1QvQ78Xif7/LKMjnt2VTYMnJyWzZsoVBgwZlOT5o0CDWrVuX52s7dOhAUFAQ/fv3548//sjy3Pr167Ndc/DgwXleMykpidjY2Cw3kfJgZI9gtr86iO8e6sYTVzemc/2quLnYCI9OYEHoCdYePE30hRTcXGy0DPJheOc6PNq3Ea4uNuZtDWfs7G2kpGVf3TbnLzNx22aDqXd0uGzwA+bI1k9P9GJUSDAn8ef68y9wxrWGuZz56xtzrpeWh8SUNF77aReAc5pw+7FoZm0K45UFO7nlo3UMem81UecTC3Td/EpKTePmD/+k79sriYy5wveIPgZzHzRLhVzpd9LwLfBuK5g+2Lxe5M4rv2Zpk1sR1Es5V4JVkCmw5Hg4czE5vMRGgBzL4MveCJBlU2CnT58mLS2NwMDALMcDAwOJjIzM8TVBQUF8+umndOrUiaSkJL7++mv69+/PypUr6dOnDwCRkZEFuibApEmTmDBhwhX2SKR08nR3JaRRdUIamUvULySnsvmIuVIroIqdVrV8aVqzcpZE6XZ1/Hhi1lZ+/juC5NR03r+zg/P5neExvLLQDDyeGdiU3k3yP3Lj6e7Ka9e3ontDf8bODuXWC/9inud/qHpyJ3xzC9yz0Cwhkg8frfyH4+cSqOXrybJxV3HqfBK7T8SyOyKG3Sdi2RoWTdjZCzw5axvfPti9yKfHPll1iK1h0QA88vVm5jzSo3CjTXuXwIJHM4rTJsdD/38XrlHp6fDz0+YHfuxxc6+m3143y6Y0GQhNB0PDfiWTHFtc0lIvvwu0g08F2wwxag9gmIVgK+ecI1jkMleEL2MsT4K+dOg4r+HkZs2a8dBDD9GxY0d69OjBhx9+yLXXXsvbb79d6GsCjB8/npiYGOft2LFjheyNSOnn5eFGn6Y1eLJ/E27vWo82dXyzrRK7pnVNPhnZCQ83F5btPsnor7eQmJJG9IVkRn+zheTUdAa0COCxvo0L1YZrWgfx3UPdOFepHiMS/0UMVeDEVvhuRL6+SYaducBHq8xvui9f15LKdjcaVPfm2rZBPDe4OV/e15W5j4bg7eHKhkNneW/5/kK1MzeHTsUx7Y+DAHi4ubD9eAwvzttRsGTz1GT49UWYfYcZ/DjKiqx5B9a8W7iGbZ8FEdvNIrfXvAVNBpv7LsUehy1fwqzb4bN+kFiGR7k3fgzJ56FS1YzfWW4cu0HHVJC9gJwJ0CU0+gPaCLEwqlevjqura7aRmaioqGwjOHnp3r07Bw4ccD6uWbNmga9pt9vx8fHJchOp6K5uHsj0ezvj6e7CH/tO8cBXf/HUnFCOn0ugnr8X7wxvX/hCsUCn+v78ODqEC35NuTPpX5zHC8LWmUHQ4TXmN/1cvP7zLpJT0+nVuDpDWtfM8ZzG9himDvQCDKb9cZA/9kUVuq2ZGYbBS/N3kpyazqj6p1nY7yy+LgnM2xbO9LWH83eRs4fhi0Gw4QPzcfcx8NhGGDjRfPzbBNj4acEalhRnvg7gqueg+2i463t44TDc+QN0eQgq+UPUblj0RNmcFjt31CzGCzBgArhdpkZfRdsMsaRXgEGmZfBlbwrMsgDIw8ODTp06sXz58izHly9fTkhISL6vs23bNoKCgpyPe/Toke2ay5YtK9A1RcTUu0kNZtzXFW8PV/48eIaV+05hd3Pho7s74lvJ/Yqv3zigMvMeC4Ggdtyb9Dzxht0sk/HVdfC/RjD3Idg5z6xhdtHve0+yYk8Ubi42Xru+ZfbR3TP/wLxHYHJr+v82jG1VnmGC25d8P3sGJ05HX3Gbf9xynE2HoviXx/e8enIsLdY8xlb7I8xwf4sjv77Pxu07c39xSqLZn0/6mJXKPf3g9llwzRvmh3nPJ81kUoBfnoNt3+a/YWvfg7iTUDUYuo3OOO5eySxhcu3bcOf34OIGuxeYiatliWHAkmfNqZb6PaHDyMu/JvMUWHrBytSUSY4VYIEWjABpGXzBjBs3jpEjR9K5c2d69OjBp59+SlhYGKNHm/94x48fT3h4ODNnzgRg8uTJBAcH06pVK5KTk/nmm2+YO3cuc+fOdV5z7Nix9OnTh7feeosbbriBhQsXsmLFCtauXWtJH0XKuu4NqzHzgW6M+mIT55NS+c+NrWlVy/fyL8yngCqezHmkB49+48Hwg69yn9uvXGvfTqXEaNjxvXlzcYfgnqQE92XWn5VxoSYP9GpM44AqGRc6dxRW/xdCZ4GRZh5z9aBqSiT3ukVyr7GchA/eIb3pAFxaXAstb8jIX8inM3FJTF+8mtkek+nicnFazac2rrHh9HXdTl/X7TD/C5LWdcDeqBckRMP5CDgfmbFD70VxAZ3Y3u0dIuNrcG7NIWISUmgZ5MPgPv/CJek8bPgQFj1ufsNudVOO7XFO70eHwbr3zYMDJ5o7buekbhfz+aXj4dfxULsj1O5UoN+BZXbNhwPLwNUDrpucv52dq9QEbJCeAhdOl1xejBXS0+GkmZtXoiNAhZkCS0uFn8dC10cgqG3xtCsfLA2ARowYwZkzZ3j99deJiIigdevWLFmyhPr16wMQERFBWFiY8/zk5GSeffZZwsPDqVSpEq1atWLx4sUMHTrUeU5ISAizZ8/m5Zdf5pVXXqFRo0bMmTNHewCJXIFO9auybFwfImIS6Vgv7z2ICqOy3Y0vRnXh5fmVeHZzMM+npDM88AT/angYv7AVcOYAHFqJ+6GVfAac9/Si0rk+sP4qc3+Xv+fAtq/N3YEBGg80l+TWaA6HVxH3909c2LWEAOMc7PvZvP3yL+hwN3R5AKo1ylc7F8z+nNnp/4efSzyGvQq2YVOh9c1waj8pu3/i0Jo5NEvdh/3kNji5LcdrxBt2vky7hslht5AadgLImqDbLLAKTw94gsEd4rBtm2muDnP3NkdxgLR0g+W7T/LVuiP8fTyaZwY1476I17GlJUH9XtBiWN6d6P4oHP0T9v4MP4yCR1ab+TSlWcI5+OXiyFivcVDjMqu/HFzdzSDofATEHC/fAVD0EUiOA1c7VGtScu/rTIIuwBTYbxNg2zew71d4akfGNFoJs3QfoNJK+wCJWOen7Sd4af4OYhNT8XR34eVrW3JX42Ri/l7MllWL6MIefGy5fNts2Bf6vQR1u2Z7atnOCKZ++yMDXLfysO9feMVnWuzQqD90fQiaDAKXHFZypSYR/sPz1N43A4AL1dvidedM8G+Q5bSTsYmMmvoTHRLW08c3igQPf7ac9eRYqh+RRlUiDX9i8Mbbww0/Lw/8vT3w83KnqpcHnu4u/LIzkvOJZhDXJsibz6p8Rs2wn8HFnYRez/O17Qa+2hhOeHTGdENH237m2V/DwIbtkVUQ1O7yv+SEaHMaLvooNLsWbv/WrNx7hSJiEnjuh7+p6u3B5BHti27l3U9jYcsM84P90T9zH+HKyWdXm1sDjPjm8sFhZtu+NeuNtb8r3wGypXYvhO/vgaD28MiqknvfI3/CjKHmn80Tmy9//s558ON95v3bZuQ6ullYBfn8Vi0wESlVhrWrRefgqjz7w3b+PHiGlxfs5LdmNTAIYWVSE7oH+zJrmBe2I2vg8Grzwy2wNfQdD8E9c73uoNZBbO49gMmrG/JF3HCWX59K4N6vzWmVf34zbz51wCfoYoLwxe+GhoERf4raMWbAtC7gdkIefj/HBNxAH0/euGcAIz6pzHdnM3JOqle206dJdR5tWoNeTapTvXLOH+AvDW3J52sP8cXaw+yIiKdXxHC+9I2ld9JqKq3+P7qmz2ZOymiqegVzR9d6+Hi60uP3VwD41X0ATd0aka+P6kp+MPwrmD4I9i2G9R9AyOP5eWWuDkbFcc/0jZy4uCdSr8bVGNEl9x398+3oOjP4ARg2pWDBD5h5QOFbCrYUPmoPLHzMvL/mHWg8ALo+bP7MKUAuDUqyAnxmBakFdnIXLBxj3u/5VJEHPwWlEaAcaARIxHrp6QZfrjvCW7/uJfniTtauLjaWPNmbZjWrXObVOUtJS+eOTzew+eg5WtXyYe6jIXieD4PN02Hr1xl78eTgnFGZ/7g/yWvPjqOKZ94J4Mt2RfLDluN0rFeVPk2r06KmT4FWzJ2NT+aT1f/w1bojJKakcbPLGl5zn4mP7QJpLh6k93sJ955PwI4fYP4jxONJ38R3SbBX5+3b2nJN66As14uISWDT4bNsOXqO5jV9uLPbxcDkr8/NnXxd3MzduOsVLlUg9Fg09325iXMXUqhsdyMuKZXqlT34/dm++Fzmd5Wn1CT4uLdZ+qLDSLhhWsGv8et4M58q5EkYNDF/r5n7oPm79Q6A+FM4g+GqwdDlQXNUyMs/y0siYhL436/7uCckmPZ1/Qrezis16w7Yt8Tc/qD76MufX1RO7YcPupgJ/f/Ko7Zfwjn4tK9ZyLZhP7h7brEEkwX5/FYAlAMFQCKlx77I8zw1J5Q9EbE80qch44e2uKLrRcQkMHTKGs5dSOHu7vX4z40XV8wkXzCX4acmm49tNsDGnshY3l52gC1pjXhrZF8Gt8p52X1xOHU+iS/+PMzZuGRub+5G+9B/Yzt4cZVrna4QcwzORxDX6yXu/6c3mw6bSdYP92lIoxrebDp8jk1HznDsbNYVOk/2b8LTA5pgA5j7AOycC1Vqwaifs0z3pKUb/HMqjobVvXFzzTnpePX+U4z+ZgsXktNoV8eXz+7pzO2fbeDQqXge7tOQFy/355UYY5arsLmAV3XwqmYGF17VYMNHsPIN8K4BYzY5g46k1DQ8XF3yV4Jk3fuw7GVW2a8i6fpPGXS5P78z/8C0zmCkm/lR9irw13Qzx8yxGtHuY/6uMk03PvP9duZuPU6gj51lT12Fr9eVr5IskPfaQEyYGcjmMRJa5GKOw3utzOT0V07lfE56mrm9xcHl4FcPHl6VLYAsKgqArpACIJHSJTk1nf0nz9Oqlk+R1N36Y18U9335FwDv39GBYe1yLsa65ehZRk7fxIXkNK5rG8S0Ozte8XtfEcMwk0d/HW9uBgjmB8qYv0hx8eC/v+7lszXZ9yJysUGrWr7U8/di8Y4IAB7v15hnBjXFlhxn5smc3m9+ix8+ExpeRURMAo9/t40tR89R1cud/i0CuaZVTXo1qe7c8XphaDjPfL+d1HSD3k2q8/HdnfC2uzl/v+6uNpY+1YeGNSrn3J+Ec2ZBXMf+Nbn4wH88v9p6cTY+mXMXkrmQnEajGt58dHcnmgbmPRoY+ssXtN/4NJvSm3GPMYEfR4dkKTaczcIx5u+4yWBzHyWH5AvmqND6D8wRqQZ94N6fAHPErvuk35wjlTd3rM27w9vn2a4i5RiFAXjhqDnFWVIunIX/XsyFe+UMuOaQWfPbRFjztrkp5wPLinXllwKgK6QASKT8+++ve/lw5T9Utrvx0xO9aFA965L4neEx3PHpBs4npdK7SXU+u6dzsRdWzbfoY2Zi8JG1MOJrs8TFRUt2RDD1twP4eLrTtYE/XRr407Gen3Pa7vM1h/jP4j0APNq3Ec8PboYtLgpm3wnhm8HmyoHO/2bE1lacjU/O9tbeHq70bRZA7aqV+HT1IcDM23rntnZ4uGWMEt335Sb+2HeK/s0DmD6qS/Y+JMaaNeDCt5gjP0Ft4cIZiD9DevxpXNLMXKJlaZ14OGUckD3wreLpxid3dyKkcfUcf02/7oxg+qw5/OD+KuHUoGfiFGr7VeKnJ3rh753DJorRYTC1g7ma8IHlOSbTm+d0NJfW37MIGl7FRyv/4a1f91LbrxIRMQmkG/DZPZ0Z2DL3DXjT0g0mLdnD4dPx3BMSTJ8m1QsX3Ef8Dd/cDPGnSA7qgscjKwp+jSuRkgj/d7Gf/zqWvZTNnp/MorQAN38ObW8r1uYoALpCCoBEyr/UtHTu/Hwjmw6fpUWQD/MfC3EGOPtPnmfEJ+s5dyGFrsH+fHV/Vyp5lJLgJ7PU5MvvhpyDL9Ye5vWfdwPwSJ+G/GtIc2ypSaQvegKXHeaox1epA/mxxuNMvrMzJ2MTWbbrJEt3RRJxSeHXe3vU59VhrbLlOP1zKo7B760mNd3gq/u7clXTTDXjkuPN2m9h683dqUcthsCWAPx58DRjvttK4oU4GlVO4cbeHfCv7EVVb3O1nL+3B64uNp6eE8pfR87h7mrjzZvbckunOlne/9edkTz+3VZqpJ9mvecTGC7u9POcw5GziYQ0qsbM+7tmn9ZzVDZvcBXcuyj3X+CS52DTp1CnC2n3LaPP/1YSHp3Af29tyz+n4vhk1SGqV7az/Ok+VM0h0EpPN3jux7+ZuzWjSGurWj482rcRQ1oH5X/13NH15tRSUgy70oN52uPf/PDM9UWySWm+GQbG6/7YjHR4Zt/FvZcw9yU6uMJc8ZUcB90fg2smFXtzykQ1eBERK7m5uvD+HR2o5u3BnohYZ0Bw+HQ8d32+kXMXUmhX14/pozqXzuAHChX8ANzfqwETrm8FwCerD/F/i/dwKtHG3Wfu578pIwC41205C/zepVHlFEIaVee161ux7l9Xs3BMTx7t24h2dXwZP6Q5r12fPfgBaFSjMqNCggGY+PNuUtIuropLSTQTdsPWg90XRs6HwJYYhsGXfx7mni82EX0hhWZ1A/niyRt46Kqm3NKpDlc3D6RDvarUr+ZNnapefP1AN4a1q0VKmsEzP2xn8or9zlpsjuAnNd2gR7sWGDYXbOkpfH5rMF4erqz75wxv/rI3a4NjI8xEeIA+z+X9C+z9rDmdc/wv/v5jDuHRCfh5uXN9u1o8PaApTQIqczouiX8v2pXtpenpBi/O38HcrcdxdbFxU4faVHJ3ZdeJWB7/bhsD3l3F7E1hJKWm5d2GA8vh65sgKYZ99jbcnvwy++M8i7zu3eWkGZCAuTJv68Hj5pTYn1Ph/Y7w3W1m8BPcGwa+XqLtyg+NAOVAI0AiFcfq/ae498tNGAaMH9Kcr9Yd4URMIs1rVmH2w93x8ypckFEWfL3hKK8sMJdPV3J3JSElDS8PV77sdpJuof8ylzZXa2wGBE2vuXxuSUoChG0wE8hrdyIm3ZOr317JmfhkXh3Wkvu61TanQw4sBY/KMHIB1O1CUmoaryzYyfebzRGRmzvU5o2b21x2yjE93eB/y/bx0UqzMO7NHWvTv3kgY2dvIzXd4Ib2tXh3eHtc32sJ50/AQ7/zy9laPPrtVgCm3N6eG9pfLJex9CVYPw3qdof7f738vkjLX4U/JxPm3pCrzr/Ow30aOxP0/z4ezU0friMt3eDDuzoytI25Ks8wDF5ZuJNvNoThYoPJt3fg+na1OBefzIx1R5ix7ggxCSkABPl68sWoLrQIyuEzaOdcmPcwpKcSXbsf3f+5h2SbnXTDzPda/GTvnF9XDGZvCuPqxb0JsEWzwdaebi57zE05wUwWb38n9P1Xts021x08Tcf6VYt8WllTYFdIAZBIxfLOsn28//tB5+NGNbyZ80iPXPfrKU++2xjGi/PNJOSmgZX58K6OZomRiL/NkZrYi9M0Lu7mRpMtrzc3T/SuZiZln9pn7qF08Ddzh+nUi1NkNhcIaMUBe0umHazGQY/mzG+yFI8Di83Rk7t/JDqgK9vConn/9wNsDYvGxQYvDm3BA70aFCgf5ruNYbyycCdp6RkfZ87gx8UGnw+A43/B8K+h5fX8b+lePvjjHzzdXcykaL8UmNzGDPjumgtNBlz+TS+cJX1yW1ySz/N4yhO88MyL1PXP2NHY8XfK39uDZU/3oZq3BxN+2s2MdUew2eDd4e24qUPWabv4pFRmbQrj8zWHiYw1g/CFj/fE7pYpSNj8Bfw8DjAwWt/C7VH3sjEsjju71SP6QjJLdkTStYE/cx7uXiQLBvISk5DC1W+vZG7KGIJdTjqPGzXbYuvyILS5NcdyMyt2n+SRb7bQNdifL0Z1KdIRVm2EKCJSAE8NaMpfR86y4dBZ6vl78e2D3StE8ANwZ7d6BFSxsycilgd6N8DL4+LHQlBbc0fhTZ/C7kVwao+5jPngcrA9BXW7mQnBscezXtCntrm/S3QYnNxBE3YwxTGIdgDSbO58Vmsi3/+YyqHTGYWrfTzdeP/OjllzhQrQh1p+noz5divxyWnc0N5Mynbm0vhcXOV3cTPEcQObsetELCv3neKRr7ewuNUf+KVcICmgLcd9u5ESGUtqmkG9al6572Pk5c+qaiPoF/E5L1eaT03f17I8/cTVTVi++yR7I8/z8vyd1KlaiRnrjgDw1i1tswU/AN52Nx7s3ZCbOtRm0Hur2Rt5nvd/O8izg5uZJzj2bQLofD+/BT/Hxs3bsLu5MLZ/E1LTDX7fG8Wmw2dZtP1ExuhWMZn62wHOxCezp3Jr6qWfY0FKN2amDmRU11u4sWP2/gFsPHSGMd9tJS3doJZfJexu1mXiaAQoBxoBEql4YhJSWBQazuBWNQnw8bS6OaXPqf2wZ6FZciHzsnVXu7nvTKP+5k7JNZqZ00exEXB8ExzbxPkDf2I/9TcGLjyW8iS/pWcUYG1Y3ZuO9asypl/jbCvxCurI6Xh2hMcwpHXNrAnOv74IGz4w9xPqeA90vIcYe22u/2At585E8ad9LFVsCTyc/DTL0jNWrFW2uzHjvi50Ds6+Z018UipXT/qZJcbjVLOdh+unQcesFep3nYjhhml/kpppZGrSzW24o+vld8j+ZUcEj367FVcXG/MeDaFd7EqzdhsG9HyKtKtfZejUtew7eZ7RVzXiX0OaAzDt9wO8vWw/gT52fnumL5XtxTPOcTDqPNdMXmMmud/Xhasa+zN15WHeXb6fKnY3fnmqN3WqZq3xtetEDLd/Yq6sHNAikI/v7pjr/lKFpSmwK6QASEQkD2cPwaGV4FsP6ofkq5jlxPlbWLEjjHq1a9Ghrh8d6lWlfV2/HFdJFbnjW2DW7RAfdfGADRr140SjESz/4zfuTfmefUZdbkr/L26urri7upCabhCTYO5s/c2D3bLt7vztxqO8NH8nz/ss47HkGeBbF57Ykq1Ux5QVB3hvhZmYPPGGVozsEZzvZj8xaxs/bT/BLf6HeTtpAra0ZOh0H1z3HvO2hTPu++34eLqx5vmrnRsvJqakMXjyao6euVAkG4fmxDAM7vliE2sOnGZAi0A+v7czYK6sHP7JeraGRdO1gT+zHuruHIU7fDqe2z5ex+m4ZLo28Gfm/V2LZVsJBUBXSAGQiEg5k5oM+3+BzV/CoT+yP3/LdDNn5aKE5DTum7GJDYfOUsXTje8e7E6bOuYGioZhMGTKGvZGnue1IQ0Ztfkms+L8kP9Bt4ezXDYlLZ1PVx+iYXVvhrTJWqLkcs7FJ/PYuzP5JPVlfGwJ0Pw6GD6TpHTo/84qjp9L4IVrmvNo36wV4H7fe5L7Z2zGzcXGr0/1oXFA9o0od5+IZe3BU1TycMOvkrnFgJ+Xu7M4r3ceI0fLd5/koZmb8XB1Yfm4PtSvljFyd/RMPEOnrCE+Oc3ZtpOxidzy0TqOn0ugZZAPsx/pfmUlUvKgAOgKKQASESnHzh6GrTPNHZ/jo6B6M3hsfbbaVPFJqYz6chN/HTmHbyV3Zj3UnZa1fNh46AwjPt1AJXdXNrzYH9+dX5m5Od4BMDY0x8TfQjl3hKRPBmBPPMXG9OZ4jFpAh4ZBfPnnYSb8tJtAHzsrn+2XYxLxAzP+4re9UfRqXJ2vH+iKzWYjLd1g+e5IvvzzCBsvlk3JTZ+mNXj52hbZdtpOSk1j0HvmCNOjfRvxwjXNs732+83HeP7Hv3F3tTHjvq68/tNu9p08T3A1L34YHUKNKsWXX6cA6AopABIRqQDSUsz9iKo3gyo579ocl5TKyOkb2RYWjb+3B7Me6s7U3w+w+O8I7uhal0k3tzVHl6Z1huijULUB1OoAga2gZhvzp0/tyy+rv1T8aZg+CM7+wwl7Q66JGU/1GgF8/0gPBr+3mjPxybxxU5uMwraXOHomnoHvriY5LZ3/3tKW6IRkvlp3lPBosy6cq4uNvk1r4O7qwrkLyURfSCE6IZlzF1KcJT1cbHBXt/o8PbCpc+fsD1ce5L+/7iOgip3fn805x8gwDB79Ziu/7op0Hgv0sfPj6JAsK+WKgwKgK6QASEREHGITU7j78438fTyG6pU9iL6QQmq6wZIne9Oy1sXPiL2LzSTltOzlQ/D0NYvXNu4Pja6G6k3zDojiTsF3w+HEVvCtS8ydSxj4+X6izidRp2oljp9LoEF1b5Y93Qf3PJKIL93eAaCqlzt3dqvH3d3rE+RbKdtrDMPg6JkLvPnLXmcAU8XTjbH9m3BN65oMem81F5LTeHd4O27OZaUXmNN3gyevJup8Er6V3Pn+kR40q5l33baioADoCikAEhGRzGIupHDHZxvYHRELQJfgqvwwOiTrSXFRELEdTu6Ek7vM2+n9Zm2xzHzqQOOrzWDIt565xcDJ3RB18RZ3cU+dSv5w/1Ko0ZTf9pzkga82Oy8x7c4OXNc25yK+DgnJaQyavIpjZxNoXrMK9/UM5ob2tfOdfLz+nzNM/Hm3s88ebi4kp6bTsZ4fP44OyXEH8My2H4vm87WHeah3A9rW8cvXe14pBUBXSAGQiIhc6mx8Mnd+toG9kef5ZGQnBreqefkXpSZB1B44vBr++R2OrgPHTsl5qdEcbvgQ6mRsGfDsD9v5cctxWtf2YdGYXpcNQADOxCUREZNIq1o+hdoYMS3d4Mctx/jf0n2cjkvGZoOFY3qWWEBTUAqArpACIBERyUlCchr/nIqjdW3fwl0g+YIZBP3zmxkQJZwz904KaAUBLSCgJQQ0B3v26aKE5DRmbQpjYMvAYs+ludT5xBS+2xhGTV/PYt9g8UooALpCCoBERETKHlWDFxEREcmDAiARERGpcBQAiYiISIWjAEhEREQqHAVAIiIiUuEoABIREZEKRwGQiIiIVDgKgERERKTCUQAkIiIiFY4CIBEREalwFACJiIhIhaMASERERCocBUAiIiJS4SgAEhERkQrHzeoGlEaGYQAQGxtrcUtEREQkvxyf247P8bwoAMrB+fPnAahbt67FLREREZGCOn/+PL6+vnmeYzPyEyZVMOnp6Zw4cYIqVapgs9mK9NqxsbHUrVuXY8eO4ePjU6TXLs0qar9Bfa+Ifa+o/Qb1vSL2vTT12zAMzp8/T61atXBxyTvLRyNAOXBxcaFOnTrF+h4+Pj6W/0WxQkXtN6jvFbHvFbXfoL5XxL6Xln5fbuTHQUnQIiIiUuEoABIREZEKRwFQCbPb7bz66qvY7Xarm1KiKmq/QX2viH2vqP0G9b0i9r2s9ltJ0CIiIlLhaARIREREKhwFQCIiIlLhKAASERGRCkcBkIiIiFQ4CoBK0IcffkiDBg3w9PSkU6dOrFmzxuomFbnVq1czbNgwatWqhc1mY8GCBVmeNwyD1157jVq1alGpUiX69u3Lrl27rGlsEZo0aRJdunShSpUqBAQEcOONN7Jv374s55TXvn/00Ue0bdvWuQlajx49+OWXX5zPl9d+X2rSpEnYbDaeeuop57Hy2vfXXnsNm82W5VazZk3n8+W13w7h4eHcfffdVKtWDS8vL9q3b8+WLVucz5fH/gcHB2f7M7fZbIwZMwYoo302pETMnj3bcHd3Nz777DNj9+7dxtixYw1vb2/j6NGjVjetSC1ZssR46aWXjLlz5xqAMX/+/CzPv/nmm0aVKlWMuXPnGjt27DBGjBhhBAUFGbGxsdY0uIgMHjzY+PLLL42dO3caoaGhxrXXXmvUq1fPiIuLc55TXvu+aNEiY/Hixca+ffuMffv2GS+++KLh7u5u7Ny50zCM8tvvzDZt2mQEBwcbbdu2NcaOHes8Xl77/uqrrxqtWrUyIiIinLeoqCjn8+W134ZhGGfPnjXq169vjBo1yti4caNx+PBhY8WKFcbBgwed55TH/kdFRWX5816+fLkBGH/88YdhGGWzzwqASkjXrl2N0aNHZznWvHlz41//+pdFLSp+lwZA6enpRs2aNY0333zTeSwxMdHw9fU1Pv74YwtaWHyioqIMwFi1apVhGBWr74ZhGFWrVjU+//zzCtHv8+fPG02aNDGWL19uXHXVVc4AqDz3/dVXXzXatWuX43Plud+GYRgvvPCC0atXr1yfL+/9dxg7dqzRqFEjIz09vcz2WVNgJSA5OZktW7YwaNCgLMcHDRrEunXrLGpVyTt8+DCRkZFZfg92u52rrrqq3P0eYmJiAPD39wcqTt/T0tKYPXs28fHx9OjRo0L0e8yYMVx77bUMGDAgy/Hy3vcDBw5Qq1YtGjRowO23386hQ4eA8t/vRYsW0blzZ2677TYCAgLo0KEDn332mfP58t5/MD/TvvnmG+6//35sNluZ7bMCoBJw+vRp0tLSCAwMzHI8MDCQyMhIi1pV8hx9Le+/B8MwGDduHL169aJ169ZA+e/7jh07qFy5Mna7ndGjRzN//nxatmxZ7vs9e/Zstm7dyqRJk7I9V5773q1bN2bOnMnSpUv57LPPiIyMJCQkhDNnzpTrfgMcOnSIjz76iCZNmrB06VJGjx7Nk08+ycyZM4Hy/efusGDBAqKjoxk1ahRQdvusavAlyGazZXlsGEa2YxVBef89PP744/z999+sXbs223Plte/NmjUjNDSU6Oho5s6dy7333suqVaucz5fHfh87doyxY8eybNkyPD09cz2vPPZ9yJAhzvtt2rShR48eNGrUiK+++oru3bsD5bPfAOnp6XTu3Jk33ngDgA4dOrBr1y4++ugj7rnnHud55bX/ANOnT2fIkCHUqlUry/Gy1meNAJWA6tWr4+rqmi0SjoqKyhYxl2eOVSLl+ffwxBNPsGjRIv744w/q1KnjPF7e++7h4UHjxo3p3LkzkyZNol27dkyZMqVc93vLli1ERUXRqVMn3NzccHNzY9WqVUydOhU3Nzdn/8pj3y/l7e1NmzZtOHDgQLn+MwcICgqiZcuWWY61aNGCsLAwoPz/Wz969CgrVqzgwQcfdB4rq31WAFQCPDw86NSpE8uXL89yfPny5YSEhFjUqpLXoEEDatasmeX3kJyczKpVq8r878EwDB5//HHmzZvH77//ToMGDbI8X577nhPDMEhKSirX/e7fvz87duwgNDTUeevcuTN33XUXoaGhNGzYsNz2/VJJSUns2bOHoKCgcv1nDtCzZ89sW1zs37+f+vXrA+X/3/qXX35JQEAA1157rfNYme2zRcnXFY5jGfz06dON3bt3G0899ZTh7e1tHDlyxOqmFanz588b27ZtM7Zt22YAxrvvvmts27bNudz/zTffNHx9fY158+YZO3bsMO64445Sv1QyPx599FHD19fXWLlyZZalohcuXHCeU177Pn78eGP16tXG4cOHjb///tt48cUXDRcXF2PZsmWGYZTffuck8yowwyi/fX/mmWeMlStXGocOHTI2bNhgXHfddUaVKlWc/5+V134bhrnlgZubm/F///d/xoEDB4xvv/3W8PLyMr755hvnOeW1/2lpaUa9evWMF154IdtzZbHPCoBK0AcffGDUr1/f8PDwMDp27OhcIl2e/PHHHwaQ7XbvvfcahmEuEX311VeNmjVrGna73ejTp4+xY8cOaxtdBHLqM2B8+eWXznPKa9/vv/9+59/rGjVqGP3793cGP4ZRfvudk0sDoPLad8ceL+7u7katWrWMm2++2di1a5fz+fLab4effvrJaN26tWG3243mzZsbn376aZbny2v/ly5dagDGvn37sj1XFvtsMwzDsGToSURERMQiygESERGRCkcBkIiIiFQ4CoBERESkwlEAJCIiIhWOAiARERGpcBQAiYiISIWjAEhEREQqHAVAIiIiUuEoABIRyYeVK1dis9mIjo62uikiUgQUAImIiEiFowBIREREKhwFQCJSJhiGwX//+18aNmxIpUqVaNeuHT/++COQMT21ePFi2rVrh6enJ926dWPHjh1ZrjF37lxatWqF3W4nODiYd955J8vzSUlJPP/889StWxe73U6TJk2YPn16lnO2bNlC586d8fLyIiQkhH379hVvx0WkWCgAEpEy4eWXX+bLL7/ko48+YteuXTz99NPcfffdrFq1ynnOc889x9tvv81ff/1FQEAA119/PSkpKYAZuAwfPpzbb7+dHTt28Nprr/HKK68wY8YM5+vvueceZs+ezdSpU9mzZw8ff/wxlStXztKOl156iXfeeYfNmzfj5ubG/fffXyL9F5GipWrwIlLqxcfHU716dX7//Xd69OjhPP7ggw9y4cIFHn74Yfr168fs2bMZMWIEAGfPnqVOnTrMmDGD4cOHc9ddd3Hq1CmWLVvmfP3zzz/P4sWL2bVrF/v376dZs2YsX76cAQMGZGvDypUr6devHytWrKB///4ALFmyhGuvvZaEhAQ8PT2L+bcgIkVJI0AiUurt3r2bxMREBg4cSOXKlZ23mTNn8s8//zjPyxwc+fv706xZM/bs2QPAnj176NmzZ5br9uzZkwMHDpCWlkZoaCiurq5cddVVebalbdu2zvtBQUEAREVFXXEfRaRkuVndABGRy0lPTwdg8eLF1K5dO8tzdrs9SxB0KZvNBpg5RI77DpkHwCtVqpSvtri7u2e7tqN9IlJ2aARIREq9li1bYrfbCQsLo3HjxlludevWdZ63YcMG5/1z586xf/9+mjdv7rzG2rVrs1x33bp1NG3aFFdXV9q0aUN6enqWnCIRKb80AiQipV6VKlV49tlnefrpp0lPT6dXr17Exsaybt06KleuTP369QF4/fXXqVatGoGBgbz00ktUr16dG2+8EYBnnnmGLl26MHHiREaMGMH69euZNm0aH374IQDBwcHce++93H///UydOpV27dpx9OhRoqKiGD58uFVdF5FiogBIRMqEiRMnEhAQwKRJkzh06BB+fn507NiRF1980TkF9eabbzJ27FgOHDhAu3btWLRoER4eHgB07NiR77//nn//+99MnDiRoKAgXn/9dUaNGuV8j48++ogXX3yRxx57jDNnzlCvXj1efPFFK7orIsVMq8BEpMxzrNA6d+4cfn5+VjdHRMoA5QCJiIhIhaMASERERCocTYGJiIhIhaMRIBEREalwFACJiIhIhaMASERERCocBUAiIiJS4SgAEhERkQpHAZCIiIhUOAqAREREpMJRACQiIiIVzv8DPIcJg5woFf4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train','val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 4s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "model.load_weights(checkpoint_filepath)\n",
    "y_preds = model.predict({\n",
    "                        'text_embeddings': dict(X_test_tokenized), \n",
    "                        'image_embeddings': X_image_test,\n",
    "                        'audio_embeddings': X_audio_test}\n",
    "                                        , batch_size=1)\n",
    "y_true=np.argmax(y_test, axis=1)\n",
    "predictions = np.argmax(y_preds, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.86      0.75        14\n",
      "           1       0.88      0.71      0.79        21\n",
      "\n",
      "    accuracy                           0.77        35\n",
      "   macro avg       0.77      0.79      0.77        35\n",
      "weighted avg       0.80      0.77      0.77        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(predictions, y_true))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
